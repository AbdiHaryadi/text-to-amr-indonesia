{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ef34de9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T07:59:51.621487Z",
     "iopub.status.busy": "2022-05-18T07:59:51.619930Z",
     "iopub.status.idle": "2022-05-18T08:00:30.330445Z",
     "shell.execute_reply": "2022-05-18T08:00:30.329792Z",
     "shell.execute_reply.started": "2022-05-18T07:58:29.043157Z"
    },
    "papermill": {
     "duration": 38.742398,
     "end_time": "2022-05-18T08:00:30.330609",
     "exception": false,
     "start_time": "2022-05-18T07:59:51.588211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.15.0)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (0.1.96)\r\n",
      "Collecting indobenchmark-toolkit==0.0.4\r\n",
      "  Downloading indobenchmark_toolkit-0.0.4-py3-none-any.whl (8.0 kB)\r\n",
      "Collecting sacrebleu\r\n",
      "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\r\n",
      "     |████████████████████████████████| 90 kB 357 kB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.7.1 in /opt/conda/lib/python3.7/site-packages (from indobenchmark-toolkit==0.0.4) (1.9.1)\r\n",
      "Collecting sentencepiece\r\n",
      "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\r\n",
      "     |████████████████████████████████| 1.2 MB 1.3 MB/s            \r\n",
      "\u001b[?25hCollecting datasets==1.4.1\r\n",
      "  Downloading datasets-1.4.1-py3-none-any.whl (186 kB)\r\n",
      "     |████████████████████████████████| 186 kB 19.2 MB/s            \r\n",
      "\u001b[?25hCollecting tqdm<4.50.0,>=4.27\r\n",
      "  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\r\n",
      "     |████████████████████████████████| 69 kB 5.6 MB/s             \r\n",
      "\u001b[?25hCollecting huggingface-hub==0.0.2\r\n",
      "  Downloading huggingface_hub-0.0.2-py3-none-any.whl (24 kB)\r\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (6.0.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (4.11.2)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (0.70.12.2)\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (0.3.4)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (1.3.5)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (1.20.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (2.26.0)\r\n",
      "Collecting xxhash\r\n",
      "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\r\n",
      "     |████████████████████████████████| 212 kB 19.0 MB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (2022.2.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub==0.0.2->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (3.4.2)\r\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.47)\r\n",
      "Collecting transformers\r\n",
      "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\r\n",
      "     |████████████████████████████████| 4.2 MB 19.0 MB/s            \r\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\r\n",
      "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\r\n",
      "     |████████████████████████████████| 6.6 MB 44.1 MB/s            \r\n",
      "\u001b[?25hCollecting transformers\r\n",
      "  Downloading transformers-4.19.1-py3-none-any.whl (4.2 MB)\r\n",
      "     |████████████████████████████████| 4.2 MB 49.6 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.19.0-py3-none-any.whl (4.2 MB)\r\n",
      "     |████████████████████████████████| 4.2 MB 51.4 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\r\n",
      "     |████████████████████████████████| 4.0 MB 49.4 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\r\n",
      "     |████████████████████████████████| 3.8 MB 59.0 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\r\n",
      "     |████████████████████████████████| 3.5 MB 50.0 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.16.1-py3-none-any.whl (3.5 MB)\r\n",
      "     |████████████████████████████████| 3.5 MB 55.8 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.16.0-py3-none-any.whl (3.5 MB)\r\n",
      "     |████████████████████████████████| 3.5 MB 41.6 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.14.1-py3-none-any.whl (3.4 MB)\r\n",
      "     |████████████████████████████████| 3.4 MB 48.0 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.13.0-py3-none-any.whl (3.3 MB)\r\n",
      "     |████████████████████████████████| 3.3 MB 44.0 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\r\n",
      "     |████████████████████████████████| 3.1 MB 53.2 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.12.4-py3-none-any.whl (3.1 MB)\r\n",
      "     |████████████████████████████████| 3.1 MB 52.3 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.12.3-py3-none-any.whl (3.1 MB)\r\n",
      "     |████████████████████████████████| 3.1 MB 55.8 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.12.2-py3-none-any.whl (3.1 MB)\r\n",
      "     |████████████████████████████████| 3.1 MB 45.4 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.12.1-py3-none-any.whl (3.1 MB)\r\n",
      "     |████████████████████████████████| 3.1 MB 43.6 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.12.0-py3-none-any.whl (3.1 MB)\r\n",
      "     |████████████████████████████████| 3.1 MB 56.2 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\r\n",
      "     |████████████████████████████████| 2.9 MB 48.2 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.11.2-py3-none-any.whl (2.9 MB)\r\n",
      "     |████████████████████████████████| 2.9 MB 56.0 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.11.1-py3-none-any.whl (2.9 MB)\r\n",
      "     |████████████████████████████████| 2.9 MB 53.1 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.11.0-py3-none-any.whl (2.9 MB)\r\n",
      "     |████████████████████████████████| 2.9 MB 47.4 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.10.3-py3-none-any.whl (2.8 MB)\r\n",
      "     |████████████████████████████████| 2.8 MB 48.9 MB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\r\n",
      "  Downloading transformers-4.10.2-py3-none-any.whl (2.8 MB)\r\n",
      "     |████████████████████████████████| 2.8 MB 55.9 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.10.1-py3-none-any.whl (2.8 MB)\r\n",
      "     |████████████████████████████████| 2.8 MB 49.0 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\r\n",
      "     |████████████████████████████████| 2.8 MB 49.7 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\r\n",
      "     |████████████████████████████████| 2.6 MB 51.3 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\r\n",
      "     |████████████████████████████████| 2.6 MB 52.7 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.9.0-py3-none-any.whl (2.6 MB)\r\n",
      "     |████████████████████████████████| 2.6 MB 49.7 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.8.2-py3-none-any.whl (2.5 MB)\r\n",
      "     |████████████████████████████████| 2.5 MB 45.7 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.8.1-py3-none-any.whl (2.5 MB)\r\n",
      "     |████████████████████████████████| 2.5 MB 48.9 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.8.0-py3-none-any.whl (2.5 MB)\r\n",
      "     |████████████████████████████████| 2.5 MB 50.2 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.7.0-py3-none-any.whl (2.5 MB)\r\n",
      "     |████████████████████████████████| 2.5 MB 45.9 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.6.1-py3-none-any.whl (2.2 MB)\r\n",
      "     |████████████████████████████████| 2.2 MB 47.3 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.6.0-py3-none-any.whl (2.3 MB)\r\n",
      "     |████████████████████████████████| 2.3 MB 54.3 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\r\n",
      "     |████████████████████████████████| 2.1 MB 51.6 MB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (0.8.9)\r\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (2.4.0)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (0.4.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (1.26.7)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (3.1)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (2.0.9)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (2021.10.8)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.7.1->indobenchmark-toolkit==0.0.4) (4.1.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (3.6.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (3.0.6)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (2021.3)\r\n",
      "Installing collected packages: tqdm, xxhash, huggingface-hub, transformers, sentencepiece, datasets, sacrebleu, indobenchmark-toolkit\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.62.3\r\n",
      "    Uninstalling tqdm-4.62.3:\r\n",
      "      Successfully uninstalled tqdm-4.62.3\r\n",
      "  Attempting uninstall: huggingface-hub\r\n",
      "    Found existing installation: huggingface-hub 0.2.1\r\n",
      "    Uninstalling huggingface-hub-0.2.1:\r\n",
      "      Successfully uninstalled huggingface-hub-0.2.1\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.15.0\r\n",
      "    Uninstalling transformers-4.15.0:\r\n",
      "      Successfully uninstalled transformers-4.15.0\r\n",
      "  Attempting uninstall: sentencepiece\r\n",
      "    Found existing installation: sentencepiece 0.1.96\r\n",
      "    Uninstalling sentencepiece-0.1.96:\r\n",
      "      Successfully uninstalled sentencepiece-0.1.96\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "beatrix-jupyterlab 3.1.6 requires google-cloud-bigquery-storage, which is not installed.\r\n",
      "spacy 3.2.2 requires typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.1.1 which is incompatible.\r\n",
      "featuretools 1.6.0 requires numpy>=1.21.0, but you have numpy 1.20.3 which is incompatible.\r\n",
      "cached-path 1.0.2 requires huggingface-hub<0.3.0,>=0.0.12, but you have huggingface-hub 0.0.2 which is incompatible.\r\n",
      "cached-path 1.0.2 requires tqdm<4.63,>=4.62, but you have tqdm 4.49.0 which is incompatible.\r\n",
      "allennlp 2.9.0 requires huggingface-hub>=0.0.16, but you have huggingface-hub 0.0.2 which is incompatible.\r\n",
      "allennlp 2.9.0 requires tqdm>=4.62, but you have tqdm 4.49.0 which is incompatible.\u001b[0m\r\n",
      "Successfully installed datasets-1.4.1 huggingface-hub-0.0.2 indobenchmark-toolkit-0.0.4 sacrebleu-2.0.0 sentencepiece-0.1.95 tqdm-4.49.0 transformers-4.5.1 xxhash-3.0.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers sentencepiece indobenchmark-toolkit==0.0.4 sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10d6e664",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T08:00:30.535229Z",
     "iopub.status.busy": "2022-05-18T08:00:30.529841Z",
     "iopub.status.idle": "2022-05-18T08:00:35.364416Z",
     "shell.execute_reply": "2022-05-18T08:00:35.363042Z",
     "shell.execute_reply.started": "2022-05-18T07:59:01.201387Z"
    },
    "papermill": {
     "duration": 4.934846,
     "end_time": "2022-05-18T08:00:35.364561",
     "exception": false,
     "start_time": "2022-05-18T08:00:30.429715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'amr-to-text-indonesia'...\r\n",
      "remote: Enumerating objects: 1903, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (48/48), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (47/47), done.\u001b[K\r\n",
      "remote: Total 1903 (delta 2), reused 1 (delta 1), pack-reused 1855\u001b[K\r\n",
      "Receiving objects: 100% (1903/1903), 13.03 MiB | 6.72 MiB/s, done.\r\n",
      "Resolving deltas: 100% (768/768), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://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@github.com/taufiqhusada/amr-to-text-indonesia.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7047e5d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T08:00:35.580052Z",
     "iopub.status.busy": "2022-05-18T08:00:35.574428Z",
     "iopub.status.idle": "2022-05-18T08:00:50.061318Z",
     "shell.execute_reply": "2022-05-18T08:00:50.060860Z",
     "shell.execute_reply.started": "2022-05-18T07:59:06.961607Z"
    },
    "papermill": {
     "duration": 14.594927,
     "end_time": "2022-05-18T08:00:50.061455",
     "exception": false,
     "start_time": "2022-05-18T08:00:35.466528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'amr-indo-dataset'...\r\n",
      "remote: Enumerating objects: 66, done.\u001b[K\r\n",
      "remote: Total 66 (delta 0), reused 0 (delta 0), pack-reused 66\u001b[K\r\n",
      "Unpacking objects: 100% (66/66), 60.94 MiB | 5.58 MiB/s, done.\r\n",
      "Updating files: 100% (52/52), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://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@github.com/taufiqhusada/amr-indo-dataset.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e23d047",
   "metadata": {
    "papermill": {
     "duration": 0.290885,
     "end_time": "2022-05-18T08:00:50.465156",
     "exception": false,
     "start_time": "2022-05-18T08:00:50.174271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Finetune indot5 with linearized penman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4e55dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T08:00:50.700151Z",
     "iopub.status.busy": "2022-05-18T08:00:50.699203Z",
     "iopub.status.idle": "2022-05-18T08:00:50.703648Z",
     "shell.execute_reply": "2022-05-18T08:00:50.703228Z"
    },
    "papermill": {
     "duration": 0.125017,
     "end_time": "2022-05-18T08:00:50.703790",
     "exception": false,
     "start_time": "2022-05-18T08:00:50.578773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/amr-to-text-indonesia/train\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/amr-to-text-indonesia/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7ac5e9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T08:00:50.931829Z",
     "iopub.status.busy": "2022-05-18T08:00:50.931053Z",
     "iopub.status.idle": "2022-05-18T08:11:14.877683Z",
     "shell.execute_reply": "2022-05-18T08:11:14.877147Z"
    },
    "papermill": {
     "duration": 624.061865,
     "end_time": "2022-05-18T08:11:14.877812",
     "exception": false,
     "start_time": "2022-05-18T08:00:50.815947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\r\n",
      "Downloading: 100%|████████████████████████████| 777k/777k [00:01<00:00, 647kB/s]\r\n",
      "Downloading: 100%|██████████████████████████████| 696/696 [00:00<00:00, 519kB/s]\r\n",
      "Downloading: 100%|███████████████████████████| 990M/990M [02:24<00:00, 6.85MB/s]\r\n",
      "added 9 tokens\r\n",
      "len train dataset:  2648\r\n",
      "len dev dataset:  19\r\n",
      "len test dataset: 306\r\n",
      "len train dataloader:  662\r\n",
      "(Epoch 1) TRAIN LOSS:2.7781 LR:0.00010000: 100%|█| 662/662 [01:24<00:00,  7.80it\r\n",
      "(Epoch 1) DEV LOSS:7.6389 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 27.31it/s]\r\n",
      "bleu score on dev:  0.9750760375995845\r\n",
      "(Epoch 2) TRAIN LOSS:5.1025 LR:0.00010000: 100%|█| 662/662 [01:24<00:00,  7.84it\r\n",
      "(Epoch 2) DEV LOSS:1.7064 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 32.85it/s]\r\n",
      "bleu score on dev:  17.56128478482164\r\n",
      "(Epoch 3) TRAIN LOSS:1.6329 LR:0.00010000: 100%|█| 662/662 [01:24<00:00,  7.85it\r\n",
      "(Epoch 3) DEV LOSS:1.1906 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 31.94it/s]\r\n",
      "bleu score on dev:  26.583318552734863\r\n",
      "(Epoch 4) TRAIN LOSS:1.0766 LR:0.00010000: 100%|█| 662/662 [01:25<00:00,  7.78it\r\n",
      "(Epoch 4) DEV LOSS:0.7588 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 32.28it/s]\r\n",
      "bleu score on dev:  39.296245282119386\r\n",
      "(Epoch 5) TRAIN LOSS:0.7720 LR:0.00010000: 100%|█| 662/662 [01:23<00:00,  7.93it\r\n",
      "(Epoch 5) DEV LOSS:0.7447 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 30.70it/s]\r\n",
      "bleu score on dev:  38.93927240957322\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:18<00:00,  4.26it/s]\r\n",
      "sample:  balon ditipu oleh ilham ---- balon itu ditiup ilham\r\n",
      "sample:  puisi ditulis oleh obe ---- obe menulis puisi\r\n",
      "sample:  saya mengetik makalah ---- saya mengetik makalah\r\n",
      "sample:  anak ajaib yang angga anak yang ajaib ---- angga anak ajaib\r\n",
      "sample:  ibu seorang dosen ---- ibuku seorang dosen\r\n",
      "bleu score on test dataset:  39.79074619078503\r\n",
      "saya mengetik makalah\r\n"
     ]
    }
   ],
   "source": [
    "!python train_indoT5.py --model_type indo-t5 --n_epochs 5 --lr 0.0001 --data_folder ../data/preprocessed_data/linearized_penman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "467b6cdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T08:11:19.301705Z",
     "iopub.status.busy": "2022-05-18T08:11:19.300903Z",
     "iopub.status.idle": "2022-05-18T08:11:20.020238Z",
     "shell.execute_reply": "2022-05-18T08:11:20.019536Z"
    },
    "papermill": {
     "duration": 2.829131,
     "end_time": "2022-05-18T08:11:20.020386",
     "exception": false,
     "start_time": "2022-05-18T08:11:17.191255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu_score_test.txt  model\t\t   test_label.txt\r\n",
      "loss_data.tsv\t     test_generations.txt  tokenizer\r\n"
     ]
    }
   ],
   "source": [
    "!ls result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "515c378f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T08:11:24.710468Z",
     "iopub.status.busy": "2022-05-18T08:11:24.709710Z",
     "iopub.status.idle": "2022-05-18T08:12:36.866966Z",
     "shell.execute_reply": "2022-05-18T08:12:36.865575Z"
    },
    "papermill": {
     "duration": 74.275316,
     "end_time": "2022-05-18T08:12:36.867098",
     "exception": false,
     "start_time": "2022-05-18T08:11:22.591782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: result/ (stored 0%)\r\n",
      "  adding: result/test_generations.txt (deflated 63%)\r\n",
      "  adding: result/model/ (stored 0%)\r\n",
      "  adding: result/model/pytorch_model.bin (deflated 11%)\r\n",
      "  adding: result/model/config.json (deflated 44%)\r\n",
      "  adding: result/loss_data.tsv (deflated 36%)\r\n",
      "  adding: result/tokenizer/ (stored 0%)\r\n",
      "  adding: result/tokenizer/tokenizer_config.json (deflated 81%)\r\n",
      "  adding: result/tokenizer/added_tokens.json (deflated 42%)\r\n",
      "  adding: result/tokenizer/special_tokens_map.json (deflated 82%)\r\n",
      "  adding: result/tokenizer/spiece.model (deflated 49%)\r\n",
      "  adding: result/.gitignore (stored 0%)\r\n",
      "  adding: result/test_label.txt (deflated 60%)\r\n",
      "  adding: result/bleu_score_test.txt (stored 0%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r result_without_sta.zip result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a634a4f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T08:12:41.000015Z",
     "iopub.status.busy": "2022-05-18T08:12:40.999188Z",
     "iopub.status.idle": "2022-05-18T08:12:41.002973Z",
     "shell.execute_reply": "2022-05-18T08:12:41.002507Z"
    },
    "papermill": {
     "duration": 2.046321,
     "end_time": "2022-05-18T08:12:41.003094",
     "exception": false,
     "start_time": "2022-05-18T08:12:38.956773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/amr-to-text-indonesia/evaluate\n"
     ]
    }
   ],
   "source": [
    "%cd ../evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "035a80f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T08:12:45.916781Z",
     "iopub.status.busy": "2022-05-18T08:12:45.911407Z",
     "iopub.status.idle": "2022-05-18T08:14:44.983350Z",
     "shell.execute_reply": "2022-05-18T08:14:44.982857Z"
    },
    "papermill": {
     "duration": 121.471131,
     "end_time": "2022-05-18T08:14:44.983504",
     "exception": false,
     "start_time": "2022-05-18T08:12:43.512373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘result’: File exists\r\n",
      "saved model folder ../train/result\r\n",
      "preprocessing method linearized_penman\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data’: File exists\r\n",
      "preprocess amr_simple_test\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/amr_simple_test’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/amr_simple_test/test.amr.txt', result_sent_path='data/test/preprocessed_data/amr_simple_test/test.sent.txt', source_file_path='data/test/amr_simple_test.txt', source_folder_path=None)\r\n",
      "100%|███████████████████████████████████| 2618/2618 [00:00<00:00, 179734.31it/s]\r\n",
      "total: 306 pair sent-amr\r\n",
      "preprocess b-salah-darat\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/b-salah-darat’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/b-salah-darat/test.amr.txt', result_sent_path='data/test/preprocessed_data/b-salah-darat/test.sent.txt', source_file_path='data/test/b-salah-darat.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 676/676 [00:00<00:00, 106296.37it/s]\r\n",
      "total: 32 pair sent-amr\r\n",
      "preprocess c-gedung-roboh\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/c-gedung-roboh’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/c-gedung-roboh/test.amr.txt', result_sent_path='data/test/preprocessed_data/c-gedung-roboh/test.sent.txt', source_file_path='data/test/c-gedung-roboh.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 606/606 [00:00<00:00, 135213.76it/s]\r\n",
      "total: 29 pair sent-amr\r\n",
      "preprocess d-indo-fuji\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/d-indo-fuji’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/d-indo-fuji/test.amr.txt', result_sent_path='data/test/preprocessed_data/d-indo-fuji/test.sent.txt', source_file_path='data/test/d-indo-fuji.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 745/745 [00:00<00:00, 104245.42it/s]\r\n",
      "total: 27 pair sent-amr\r\n",
      "preprocess f-bunuh-diri\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/f-bunuh-diri’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/f-bunuh-diri/test.amr.txt', result_sent_path='data/test/preprocessed_data/f-bunuh-diri/test.sent.txt', source_file_path='data/test/f-bunuh-diri.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 468/468 [00:00<00:00, 132559.04it/s]\r\n",
      "total: 23 pair sent-amr\r\n",
      "preprocess g-gempa-dieng\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/g-gempa-dieng’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/g-gempa-dieng/test.amr.txt', result_sent_path='data/test/preprocessed_data/g-gempa-dieng/test.sent.txt', source_file_path='data/test/g-gempa-dieng.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 412/412 [00:00<00:00, 130705.18it/s]\r\n",
      "total: 19 pair sent-amr\r\n",
      "mkdir: cannot create directory ‘result’: File exists\r\n",
      "evaluate on data amr_simple_test\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 306\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:16<00:00,  4.70it/s]\r\n",
      "sample:  balon ditipu oleh ilham ---- balon itu ditiup ilham\r\n",
      "sample:  puisi ditulis oleh obe ---- obe menulis puisi\r\n",
      "sample:  saya mengetik makalah ---- saya mengetik makalah\r\n",
      "sample:  anak ajaib yang angga anak yang ajaib ---- angga anak ajaib\r\n",
      "sample:  ibu seorang dosen ---- ibuku seorang dosen\r\n",
      "sample:  dia berenang ---- dia sedang berenang\r\n",
      "sample:  buku yang hilang dicari oleh ilham ---- ilham sedang mencari bukunya yang hilang\r\n",
      "sample:  ibu menyapu halaman rumah ---- ibu sedang menyapu halaman rumah\r\n",
      "sample:  ayah sedang membajak padi di sawah ---- ayah sedang membajak padi di sawah\r\n",
      "sample:  andi pergi kemah di tepi pantai ---- andi pergi berkemah di tepi pantai\r\n",
      "bleu score on test dataset:  39.79074619078503\r\n",
      "evaluate on data b-salah-darat\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 32\r\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:04<00:00,  1.91it/s]\r\n",
      "sample:  di bandara soekarnohatta, terjadi insiden tumpang dari lion air dari mei 10 2016 ---- kantor imigrasi bandara soekarno-hatta bersama kantor otoritas bandara soekarno-hatta dan pt angkasa pura ii membahas insiden penumpang penerbangan pesawat lion air jt 161 yang tiba di jakarta dari singapura 10 mei 2016.\r\n",
      "sample:  di kantor imigrasi soekarnohatta, kepala kantor imigrasi alif suadi menyampaikan soal ---- kami meeting soal ini,\" ujar kepala kantor imigrasi soekarno-hatta alif suadi kepada tempo, sabtu malam ini, 14 mei 2016.\r\n",
      "sample:  anak teman natalie berangkat ke singapura pada pukul 18 55 ---- anak temannya natalie berangkat dari singapura dan menggunakan pesawat lion air jt 161, pada pukul 18.50.\r\n",
      "sample:  pt angkasa pura ii yang akan mengelola bandara internasional soekarnohatta ---- sekretaris perusahaan pt angkasa pura ii agus haryadi mengatakan selaku pengelola bandara internasional soekarno-hatta, pihaknya akan berkoordinasi dengan kantor otoritas bandara wilayah i terkait dengan peristiwa ini.\r\n",
      "sample:  kami bersiap-siap di bandara parkir di remote area ---- setiap pesawat yang parkir di remote area sudah kami siapkan bus untuk mengantar penumpang ke terminal.\r\n",
      "sample:  di padang, edward mengaku mendapat bantuan sopir jemput tumpang ---- terdapat sopir bus yang akan menjemput penumpang dari padang\" ujar edward.\r\n",
      "sample:  di bandara soetta, pihak otoritas bandara soetta memanggil dan melakukan investigasi ---- pihak otoritas bandara soetta akan memanggil pihak terkait dan dilakukan investigasi.\r\n",
      "sample:  kemenhub memberikan sanksi kepada pihakpihak yang lalai ---- kemenhub memberikan sanksi kepada pihak-pihak yang lalai,\" ujarnya.\r\n",
      "sample:  zara kutip cerita temannya di terminal ii ---- pesawat itu mendarat tidak di terminal ii, kata zara mengutip cerita temannya.\r\n",
      "sample:  kami bersiap-siap di bandara parkir di remote area ---- setiap pesawat yang parkir di remote area sudah kami siapkan bus untuk mengantar penumpang ke terminal.\r\n",
      "bleu score on test dataset:  6.148195649764363\r\n",
      "evaluate on data c-gedung-roboh\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 29\r\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:05<00:00,  1.57it/s]\r\n",
      "sample:  flyover yang indomobil lakukan di atas jalan boulevard bintaro xchange dan indomobil tujukan ke arah boulevard ---- pengalihan dilakukan bagi pengendara yang melaju dari arah mal bintaro xchange dan tol bintaro menuju jalan boulevard bintaro dengan menggunakan flyover di atas lampu merah indomobil.\r\n",
      "sample:  di jakarta timur, terjadi keruntuhan dan saidah saidah ---- kegagalan struktur dan kesalahan tes tanah yang mengakibatkan gedung miring juga terjadi pada menara saidah di jalan mt haryono, jakarta timur.\r\n",
      "sample:  di bintaro, terjadi peristiwa roboh gedung ---- kapolres tangerang selatan, akbp ayi supardan membenarkan peristiwa robohnya gedung di bintaro yang menarik perhatian masyarakat banyak.\r\n",
      "sample:  panin memutuskan untuk melanjutkan pembangunan gedung tersebut ---- panin memutuskan tidak melanjutkan pembangunan gedung itu karena dinyatakan tidak lulus uji kelayakan.\r\n",
      "sample:  di gedung tersebut, gedung tersebut dinyatakan lulus ujian ---- gedung tersebut dinyatakan tidak lulus uji sehingga pembangunan gedung diputuskan tidak dilanjutkan.\r\n",
      "sample:  di polres tangerang selatan, tersangka akp samian sedang melakukan selidik ---- kasat reskrim polres tangerangg selatan, akp samian mengatakan saat ini pihaknya melakukan penyelidikan untuk mengetahui penyebab runtuhnya gedung.\r\n",
      "sample:  kami masih bersiaga dalam peristiwa tersebut hingga ini ---- hingga kini kami masih mendalami peristiwa tersebut.\r\n",
      "sample:  dia menyebut dirinya sebagai korban ---- kejadian tersebut tidak timbul korban.\r\n",
      "sample:  pada akhirnya terjadi kerugian material ---- terjadi kerugian material.\r\n",
      "sample:  di sektor bintaro tangerang selatan, terjadi kecelaan ---- pembongkaran gedung di sektor 7, bintaro, tangerang selatan, diduga menyalahi prosedur.\r\n",
      "bleu score on test dataset:  6.395186702862145\r\n",
      "evaluate on data d-indo-fuji\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 27\r\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:04<00:00,  1.71it/s]\r\n",
      "sample:  indosat dengan fujitsu indonesia menandatangani nota kesepakatan dalam rangka meningkatkan jaringan bisnis ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah dibangun dalam menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  indosat dengan fujitsu indonesia menandatangani nota kesepakatan dalam rangka meningkatkan jaringan bisnis ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah dibangun dalam menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  smart mobility iot dan iot mengubah cara usaha dalam mengelola aset ---- smart mobility dan iot mengalami perkembangan cukup signifikan sehingga mengubah cara perusahaan dalam mengelola aset.\r\n",
      "sample:  indosat dengan fujitsu indonesia menandatangani nota kesepakatan dalam rangka meningkatkan jaringan bisnis ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  di sektor transportasi dan otomotif, kerja sama dilakukan oleh perusahaan-perusahaan di indonesia ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "sample:  achmad sofwan menyampaikan keluhannya kepada president achmad sofwan ---- mobilitas akan menyediakan cara untuk mengoptimalkan strategi perusahaan dengan memanfaatkan aplikasi dan layanan yang dapat memproses data real-time, tutur achmad sofwan, president director fujitsu indonesia.\r\n",
      "sample:  di sektor transportasi dan otomotif, kerja sama dilakukan oleh perusahaan-perusahaan di indonesia ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "sample:  indosat ooredoo sedang mengerjakan solusi smart mobility dan fujitsu dengan indonesia ---- indosat ooredoo bekerja sama dengan fujitsu indonesia menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  achmad sofwan menyampaikan keluhannya kepada direktur fujitsu ---- president director fujitsu, achmad sofwan mengungkap, mobilitas akan menyediakan cara mengoptimalisasikan strategi perusahaan dengan memanfaatkan aplikasi dan layanan dalam aktivitas memproses data real-time.\r\n",
      "sample:  di sektor transportasi dan otomotif, kerja sama dilakukan oleh perusahaan-perusahaan di indonesia ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "bleu score on test dataset:  3.374432831402254\r\n",
      "evaluate on data f-bunuh-diri\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 23\r\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:04<00:00,  1.50it/s]\r\n",
      "sample:  di jembatan kira tingginya, ciptadi melompat ---- ciptadi dengan nekat melompat dari megatron jembatan penyeberangan orang yang tingginya diperkirakan mencapai 15 meter.\r\n",
      "sample:  di mapolrestabes bandung, hal tersebut diungkapkan oleh kasubag reny marthaliana ---- hal tersebut diungkapkan kabag ops polrestabes bandung kompol dede rojudin didampingi kasubag humas kompol reny marthaliana, saat ditemui di mapolrestabes bandung, jumat.\r\n",
      "sample:  di kota bandung, rezha mengaku warga kota bandung ---- rezha noviana, warga kota bandung mengatakan ia dan jemaat lainnya langsung memperhatikan megatron jembatan penyeberangan orang depan kantor pos besar bandung setelah bubar salat jumat di masjid raya bandung.\r\n",
      "sample:  satpam dan satpam di atas jpo ---- ketika itu, petugas linmas dan beberapa satpam berdiri di atas jpo.\r\n",
      "sample:  di alun bandung, aksi bunuh diri ---- aksi bunuh diri di alun - alun bandung belum lama ini terjadi.\r\n",
      "sample:  orang tua terjatuh di jalanan bandung ---- seorang pria tua nekat menjatuhkan diri dari jpo di alun - alun kota bandung.\r\n",
      "sample:  sudirman menjadi saksi mata bunuh diri di alun bandung ---- sudirman, anggota linmas satpol pp kota bandung yang menjadi saksi mata aksi bunuh diri di alun - alun bandung itu mengatakan, pria tersebut diperkirakan berusia 50 tahun.\r\n",
      "sample:  di depan bandung, dirinya terjatuh ---- seorang lelaki menjatuhkan diri dari megatron jembatan penyeberangan di depan pos giro besar bandung, bandung, jumat.\r\n",
      "sample:  di tengah padatnya lalu jalan asia afrika, hidup diakhiri oleh lelaki tengah baya ---- seorang lelaki tengah baya nekat mengakhiri hidupnya di tengah kepadatan lalu lintas jalan asia afrika.\r\n",
      "sample:  asia afrika dibuat oleh pria misterius ---- pria misterius yang bunuh diri dari jembatan penyeberangan orang di jalan asia afrika, bandung, jawa barat, membuat pesan sebelum nekat terjun.\r\n",
      "bleu score on test dataset:  5.822249377105071\r\n",
      "evaluate on data g-gempa-dieng\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 19\r\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:02<00:00,  1.98it/s]\r\n",
      "sample:  dieng, gempa berkekuatan 4 8 skala richter terjadi pada pukul 19 wib ---- stasiun geofisika badan meteorologi klimatologi dan geofisika banjarnegara, jawa tengah, menyatakan bahwa gempa yang mengguncang dataran tinggi dieng pukul 19.00 wib berkekuatan 4,8 pada skala richter.\r\n",
      "sample:  di desa tersebut, ada tanji yang gugur ---- pusat gempa diperkirakan berada di desa tanji gugur, kecamatan bawang, kabupaten batang.\r\n",
      "sample:  di jalan dekat kawah desa sumberejo, ditutup sementara ---- pvmbg merekomendasikan seluruh jalan yang mendekati kawah timbang di desa sumberejo sementara ditutup.\r\n",
      "sample:  dieng, kepala vulkanologi mitigasi bencana geologi terjadi pada pukul 19 wib ---- kepala pusat vulkanologi dan mitigasi bencana geologi surono mengatakan bahwa gempa yang terjadi di dataran tinggi dieng pukul 19.00 wib terekam sebanyak 86 kali.\r\n",
      "sample:  di lapangan, tim ukur konsentrasi gas dilakukan ---- penutupan ini dilakukan hingga tim di lapangan yang mengukur konsentrasi gas menyatakan tidak ada gas yang berbahaya.\r\n",
      "sample:  di jalan dekat kawah desa sumberejo, ditutup sementara ---- pvmbg merekomendasikan seluruh jalan yang mendekati kawah timbang di desa sumberejo sementara ditutup.\r\n",
      "sample:  di kawah timbang, petugas vulkanologi melakukan pemantauan dan beri informasi ---- petugas pusat vulkanologi dan mitigasi bencana geologi diterjunkan untuk memantau aktivitas kawah timbang dan memberikan informasi.\r\n",
      "sample:  di pusat vulkanologi, semua data yang dikeluarkan oleh pusat vulkanologi mitigasi bencana geologi ---- data yang dikeluarkan dari pusat vulkanologi dan mitigasi bencana geologi menyebutkan gempa mulai terasa pukul 19.00 wib dan telah terekam gempa sebanyak 86 kali.\r\n",
      "sample:  sabtu pagi, ungsi di ungsi ---- pengungsi di kabupaten banjarnegara, pada sabtu pagi mulai meninggalkan pengungsian.\r\n",
      "sample:  dieng, gempa berkekuatan 4 8 skala richter mengguncang pada pukul 19 wib ---- stasiun geofisika badan meteorologi klimatologi dan geofisika banjarnegara menyatakan gempa yang mengguncang dataran tinggi dieng pukul 19.00 wib berkekuatan 4,8 skala richter *(sr)*.\r\n",
      "bleu score on test dataset:  6.751436144181087\r\n",
      "mkdir: cannot create directory ‘result/linearized_penman’: File exists\r\n",
      "mv: cannot move 'result/amr_simple_test' to 'result/linearized_penman/amr_simple_test': Directory not empty\r\n",
      "mv: cannot move 'result/b-salah-darat' to 'result/linearized_penman/b-salah-darat': Directory not empty\r\n",
      "mv: cannot move 'result/c-gedung-roboh' to 'result/linearized_penman/c-gedung-roboh': Directory not empty\r\n",
      "mv: cannot move 'result/d-indo-fuji' to 'result/linearized_penman/d-indo-fuji': Directory not empty\r\n",
      "mv: cannot move 'result/f-bunuh-diri' to 'result/linearized_penman/f-bunuh-diri': Directory not empty\r\n",
      "mv: cannot move 'result/g-gempa-dieng' to 'result/linearized_penman/g-gempa-dieng': Directory not empty\r\n",
      "mv: cannot move 'result/linearized_penman' to a subdirectory of itself, 'result/linearized_penman/linearized_penman'\r\n"
     ]
    }
   ],
   "source": [
    "!chmod +x ./evaluate_indoT5_to_all.sh\n",
    "!mkdir result\n",
    "!./evaluate_indoT5_to_all.sh ../train/result linearized_penman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24697165",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T08:14:49.482832Z",
     "iopub.status.busy": "2022-05-18T08:14:49.482020Z",
     "iopub.status.idle": "2022-05-18T08:14:50.143516Z",
     "shell.execute_reply": "2022-05-18T08:14:50.142993Z"
    },
    "papermill": {
     "duration": 2.76253,
     "end_time": "2022-05-18T08:14:50.143645",
     "exception": false,
     "start_time": "2022-05-18T08:14:47.381115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: result/ (stored 0%)\r\n",
      "  adding: result/f-bunuh-diri/ (stored 0%)\r\n",
      "  adding: result/f-bunuh-diri/test_generations.txt (deflated 61%)\r\n",
      "  adding: result/f-bunuh-diri/test_label.txt (deflated 68%)\r\n",
      "  adding: result/f-bunuh-diri/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/amr_simple_test/ (stored 0%)\r\n",
      "  adding: result/amr_simple_test/test_generations.txt (deflated 63%)\r\n",
      "  adding: result/amr_simple_test/test_label.txt (deflated 60%)\r\n",
      "  adding: result/amr_simple_test/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/c-gedung-roboh/ (stored 0%)\r\n",
      "  adding: result/c-gedung-roboh/test_generations.txt (deflated 60%)\r\n",
      "  adding: result/c-gedung-roboh/test_label.txt (deflated 62%)\r\n",
      "  adding: result/c-gedung-roboh/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/d-indo-fuji/ (stored 0%)\r\n",
      "  adding: result/d-indo-fuji/test_generations.txt (deflated 83%)\r\n",
      "  adding: result/d-indo-fuji/test_label.txt (deflated 86%)\r\n",
      "  adding: result/d-indo-fuji/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/f-bunuh-diri/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/f-bunuh-diri/test_generations.txt (deflated 65%)\r\n",
      "  adding: result/linearized_penman/f-bunuh-diri/test_label.txt (deflated 68%)\r\n",
      "  adding: result/linearized_penman/f-bunuh-diri/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/amr_simple_test/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/amr_simple_test/test_generations.txt (deflated 62%)\r\n",
      "  adding: result/linearized_penman/amr_simple_test/test_label.txt (deflated 60%)\r\n",
      "  adding: result/linearized_penman/amr_simple_test/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/c-gedung-roboh/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/c-gedung-roboh/test_generations.txt (deflated 62%)\r\n",
      "  adding: result/linearized_penman/c-gedung-roboh/test_label.txt (deflated 62%)\r\n",
      "  adding: result/linearized_penman/c-gedung-roboh/bleu_score_test.txt (deflated 12%)\r\n",
      "  adding: result/linearized_penman/d-indo-fuji/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/d-indo-fuji/test_generations.txt (deflated 86%)\r\n",
      "  adding: result/linearized_penman/d-indo-fuji/test_label.txt (deflated 86%)\r\n",
      "  adding: result/linearized_penman/d-indo-fuji/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/b-salah-darat/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/b-salah-darat/test_generations.txt (deflated 66%)\r\n",
      "  adding: result/linearized_penman/b-salah-darat/test_label.txt (deflated 66%)\r\n",
      "  adding: result/linearized_penman/b-salah-darat/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/g-gempa-dieng/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/g-gempa-dieng/test_generations.txt (deflated 66%)\r\n",
      "  adding: result/linearized_penman/g-gempa-dieng/test_label.txt (deflated 67%)\r\n",
      "  adding: result/linearized_penman/g-gempa-dieng/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/b-salah-darat/ (stored 0%)\r\n",
      "  adding: result/b-salah-darat/test_generations.txt (deflated 61%)\r\n",
      "  adding: result/b-salah-darat/test_label.txt (deflated 66%)\r\n",
      "  adding: result/b-salah-darat/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/g-gempa-dieng/ (stored 0%)\r\n",
      "  adding: result/g-gempa-dieng/test_generations.txt (deflated 62%)\r\n",
      "  adding: result/g-gempa-dieng/test_label.txt (deflated 67%)\r\n",
      "  adding: result/g-gempa-dieng/bleu_score_test.txt (stored 0%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r result_without_sta.zip result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a839b8f",
   "metadata": {
    "papermill": {
     "duration": 2.103775,
     "end_time": "2022-05-18T08:14:54.357393",
     "exception": false,
     "start_time": "2022-05-18T08:14:52.253618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Finetune indot5 with linearized penman + tree level embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "940234e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T08:14:59.349266Z",
     "iopub.status.busy": "2022-05-18T08:14:59.348455Z",
     "iopub.status.idle": "2022-05-18T08:14:59.351256Z",
     "shell.execute_reply": "2022-05-18T08:14:59.351657Z"
    },
    "papermill": {
     "duration": 2.139075,
     "end_time": "2022-05-18T08:14:59.351826",
     "exception": false,
     "start_time": "2022-05-18T08:14:57.212751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/amr-to-text-indonesia/tree_level_embeddings\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/amr-to-text-indonesia/tree_level_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51cbe5da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T08:15:03.550106Z",
     "iopub.status.busy": "2022-05-18T08:15:03.549316Z",
     "iopub.status.idle": "2022-05-18T08:15:04.205210Z",
     "shell.execute_reply": "2022-05-18T08:15:04.204305Z"
    },
    "papermill": {
     "duration": 2.761638,
     "end_time": "2022-05-18T08:15:04.205355",
     "exception": false,
     "start_time": "2022-05-18T08:15:01.443717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "187bbb56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T08:15:08.732579Z",
     "iopub.status.busy": "2022-05-18T08:15:08.731770Z",
     "iopub.status.idle": "2022-05-18T08:22:54.375245Z",
     "shell.execute_reply": "2022-05-18T08:22:54.374751Z"
    },
    "papermill": {
     "duration": 468.041771,
     "end_time": "2022-05-18T08:22:54.375381",
     "exception": false,
     "start_time": "2022-05-18T08:15:06.333610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\r\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at Wikidepia/IndoT5-base and are newly initialized: ['encoder.tree_embed.weight']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "added 9 tokens\r\n",
      "len train dataset:  2648\r\n",
      "len dev dataset:  19\r\n",
      "len test dataset: 306\r\n",
      "len train dataloader:  662\r\n",
      "(Epoch 1) TRAIN LOSS:2.5103 LR:0.00010000: 100%|█| 662/662 [01:25<00:00,  7.78it\r\n",
      "(Epoch 1) DEV LOSS:1.5872 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 29.47it/s]\r\n",
      "bleu score on dev:  44.76096279578911\r\n",
      "(Epoch 2) TRAIN LOSS:1.2102 LR:0.00010000: 100%|█| 662/662 [01:23<00:00,  7.90it\r\n",
      "(Epoch 2) DEV LOSS:1.2154 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 29.13it/s]\r\n",
      "bleu score on dev:  34.093011287101554\r\n",
      "(Epoch 3) TRAIN LOSS:0.8014 LR:0.00010000: 100%|█| 662/662 [01:24<00:00,  7.80it\r\n",
      "(Epoch 3) DEV LOSS:0.7935 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 17.95it/s]\r\n",
      "bleu score on dev:  38.793880775077895\r\n",
      "(Epoch 4) TRAIN LOSS:0.5166 LR:0.00010000: 100%|█| 662/662 [01:24<00:00,  7.81it\r\n",
      "(Epoch 4) DEV LOSS:0.6266 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 30.78it/s]\r\n",
      "bleu score on dev:  45.90847262751481\r\n",
      "(Epoch 5) TRAIN LOSS:0.4826 LR:0.00010000: 100%|█| 662/662 [01:24<00:00,  7.82it\r\n",
      "(Epoch 5) DEV LOSS:0.7883 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 27.98it/s]\r\n",
      "bleu score on dev:  45.23374469889808\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:18<00:00,  4.15it/s]\r\n",
      "sample:  balon ditiup oleh ilham ---- balon itu ditiup ilham\r\n",
      "sample:  puisi ditulis oleh obe ---- obe menulis puisi\r\n",
      "sample:  saya mengetik makalah ---- saya mengetik makalah\r\n",
      "sample:  angga anak yang ajaib ---- angga anak ajaib\r\n",
      "sample:  ibu adalah seorang dosen ---- ibuku seorang dosen\r\n",
      "bleu score on test dataset:  38.33993975219217\r\n"
     ]
    }
   ],
   "source": [
    "!python train_indoT5.py --model_type indo-t5 --n_epochs 5 --lr 0.0001 --data_folder ../data/preprocessed_data/linearized_penman_with_tree_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "686672d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T08:23:02.648920Z",
     "iopub.status.busy": "2022-05-18T08:23:02.646628Z",
     "iopub.status.idle": "2022-05-18T08:23:03.296319Z",
     "shell.execute_reply": "2022-05-18T08:23:03.295829Z"
    },
    "papermill": {
     "duration": 5.15724,
     "end_time": "2022-05-18T08:23:03.296478",
     "exception": false,
     "start_time": "2022-05-18T08:22:58.139238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!chmod +x ./evaluate_indoT5_to_all.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3a9d474",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T08:23:10.688411Z",
     "iopub.status.busy": "2022-05-18T08:23:10.687619Z",
     "iopub.status.idle": "2022-05-18T08:25:10.378487Z",
     "shell.execute_reply": "2022-05-18T08:25:10.378011Z"
    },
    "papermill": {
     "duration": 123.365751,
     "end_time": "2022-05-18T08:25:10.378702",
     "exception": false,
     "start_time": "2022-05-18T08:23:07.012951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model folder result\r\n",
      "preprocessing method linearized_penman_with_tree_level\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data’: File exists\r\n",
      "preprocess amr_simple_test\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/amr_simple_test’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/amr_simple_test/test.amr.txt', result_sent_path='data/test/preprocessed_data/amr_simple_test/test.sent.txt', source_file_path='data/test/amr_simple_test.txt', source_folder_path=None)\r\n",
      "100%|███████████████████████████████████| 2618/2618 [00:00<00:00, 116508.44it/s]\r\n",
      "total: 306  tuple_sent_amr_level\r\n",
      "preprocess b-salah-darat\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/b-salah-darat’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/b-salah-darat/test.amr.txt', result_sent_path='data/test/preprocessed_data/b-salah-darat/test.sent.txt', source_file_path='data/test/b-salah-darat.txt', source_folder_path=None)\r\n",
      "100%|██████████████████████████████████████| 676/676 [00:00<00:00, 58318.93it/s]\r\n",
      "total: 32  tuple_sent_amr_level\r\n",
      "preprocess c-gedung-roboh\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/c-gedung-roboh’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/c-gedung-roboh/test.amr.txt', result_sent_path='data/test/preprocessed_data/c-gedung-roboh/test.sent.txt', source_file_path='data/test/c-gedung-roboh.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 606/606 [00:00<00:00, 125978.80it/s]\r\n",
      "total: 29  tuple_sent_amr_level\r\n",
      "preprocess d-indo-fuji\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/d-indo-fuji’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/d-indo-fuji/test.amr.txt', result_sent_path='data/test/preprocessed_data/d-indo-fuji/test.sent.txt', source_file_path='data/test/d-indo-fuji.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 745/745 [00:00<00:00, 115075.37it/s]\r\n",
      "total: 27  tuple_sent_amr_level\r\n",
      "preprocess f-bunuh-diri\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/f-bunuh-diri’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/f-bunuh-diri/test.amr.txt', result_sent_path='data/test/preprocessed_data/f-bunuh-diri/test.sent.txt', source_file_path='data/test/f-bunuh-diri.txt', source_folder_path=None)\r\n",
      "100%|██████████████████████████████████████| 468/468 [00:00<00:00, 88023.96it/s]\r\n",
      "total: 23  tuple_sent_amr_level\r\n",
      "preprocess g-gempa-dieng\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/g-gempa-dieng’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/g-gempa-dieng/test.amr.txt', result_sent_path='data/test/preprocessed_data/g-gempa-dieng/test.sent.txt', source_file_path='data/test/g-gempa-dieng.txt', source_folder_path=None)\r\n",
      "100%|██████████████████████████████████████| 412/412 [00:00<00:00, 84991.80it/s]\r\n",
      "total: 19  tuple_sent_amr_level\r\n",
      "evaluate on data amr_simple_test\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 306\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:15<00:00,  5.04it/s]\r\n",
      "sample:  balon ditiup oleh ilham ---- balon itu ditiup ilham\r\n",
      "sample:  puisi ditulis oleh obe ---- obe menulis puisi\r\n",
      "sample:  saya mengetik makalah ---- saya mengetik makalah\r\n",
      "sample:  angga anak yang ajaib ---- angga anak ajaib\r\n",
      "sample:  ibu adalah seorang dosen ---- ibuku seorang dosen\r\n",
      "sample:  dia yang berenang ---- dia sedang berenang\r\n",
      "sample:  ilham mencari buku yang hilang ---- ilham sedang mencari bukunya yang hilang\r\n",
      "sample:  di halaman rumah, ibu menyapu ---- ibu sedang menyapu halaman rumah\r\n",
      "sample:  di sawah, ayah membajak padi ---- ayah sedang membajak padi di sawah\r\n",
      "sample:  andi pergi ke kemah di tepi pantai ---- andi pergi berkemah di tepi pantai\r\n",
      "bleu score on test dataset:  38.33993975219217\r\n",
      "evaluate on data b-salah-darat\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 32\r\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:03<00:00,  2.03it/s]\r\n",
      "sample:  di kantor pt sama, kejadian tumpang terbangnya pesawat itu terjadi pada mei 10 2016 dan di bandara soekarnohatta, insiden tumpang terbangnya itu terjadi ---- kantor imigrasi bandara soekarno-hatta bersama kantor otoritas bandara soekarno-hatta dan pt angkasa pura ii membahas insiden penumpang penerbangan pesawat lion air jt 161 yang tiba di jakarta dari singapura 10 mei 2016.\r\n",
      "sample:  kepala kantor imigrasi soekarno suadi menyampaikan meeting kepada kami pada sabtu malam ---- kami meeting soal ini,\" ujar kepala kantor imigrasi soekarno-hatta alif suadi kepada tempo, sabtu malam ini, 14 mei 2016.\r\n",
      "sample:  anak temannya natalie berangkat ke singapura pada pukul 18 55 dan menggunakan pesawat lion air jt 161 ---- anak temannya natalie berangkat dari singapura dan menggunakan pesawat lion air jt 161, pada pukul 18.50.\r\n",
      "sample:  di bandara internasional soekarnohatta, perusahaan itu akan melakukan koordinasi dengan kantor otoritas bandara ---- sekretaris perusahaan pt angkasa pura ii agus haryadi mengatakan selaku pengelola bandara internasional soekarno-hatta, pihaknya akan berkoordinasi dengan kantor otoritas bandara wilayah i terkait dengan peristiwa ini.\r\n",
      "sample:  kami menyiapkan pesawat parkir di area remote area ---- setiap pesawat yang parkir di remote area sudah kami siapkan bus untuk mengantar penumpang ke terminal.\r\n",
      "sample:  edward mendapat sopir jemputan di padang ---- terdapat sopir bus yang akan menjemput penumpang dari padang\" ujar edward.\r\n",
      "sample:  pihak otoritas bandara soetta yang memanggil dan melakukan investigasi ---- pihak otoritas bandara soetta akan memanggil pihak terkait dan dilakukan investigasi.\r\n",
      "sample:  kemenhub memberikan sanksi kepada pihak yang lalai ---- kemenhub memberikan sanksi kepada pihak-pihak yang lalai,\" ujarnya.\r\n",
      "sample:  zara mengutip cerita temannya di terminal ii ---- pesawat itu mendarat tidak di terminal ii, kata zara mengutip cerita temannya.\r\n",
      "sample:  kami menyiapkan pesawat parkir di area remote area ---- setiap pesawat yang parkir di remote area sudah kami siapkan bus untuk mengantar penumpang ke terminal.\r\n",
      "bleu score on test dataset:  8.847431880082397\r\n",
      "evaluate on data c-gedung-roboh\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 29\r\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:03<00:00,  2.34it/s]\r\n",
      "sample:  kendaraan itu bergerak ke arah mal bintaro xchange dan flyover itu merupakan guna dari flyover atas lampu merah ---- pengalihan dilakukan bagi pengendara yang melaju dari arah mal bintaro xchange dan tol bintaro menuju jalan boulevard bintaro dengan menggunakan flyover di atas lampu merah indomobil.\r\n",
      "sample:  terjadi kegagalan dan salah satu tes tanah terjadi di menara saidah ---- kegagalan struktur dan kesalahan tes tanah yang mengakibatkan gedung miring juga terjadi pada menara saidah di jalan mt haryono, jakarta timur.\r\n",
      "sample:  kejadian di bintaro terjadi roboh gedung ---- kapolres tangerang selatan, akbp ayi supardan membenarkan peristiwa robohnya gedung di bintaro yang menarik perhatian masyarakat banyak.\r\n",
      "sample:  panin memutuskan melanjutkan pembangunan gedung itu karena nyata lulus uji kelayakan ---- panin memutuskan tidak melanjutkan pembangunan gedung itu karena dinyatakan tidak lulus uji kelayakan.\r\n",
      "sample:  gedung itu lulus uji, sehingga pembangunan putuskan untuk membangun gedung ---- gedung tersebut dinyatakan tidak lulus uji sehingga pembangunan gedung diputuskan tidak dilanjutkan.\r\n",
      "sample:  di polres tangerang selatan, kasat akp samian melakukan selidik saat ini ---- kasat reskrim polres tangerangg selatan, akp samian mengatakan saat ini pihaknya melakukan penyelidikan untuk mengetahui penyebab runtuhnya gedung.\r\n",
      "sample:  kami masih berada di dalam peristiwa itu sampai ini ---- hingga kini kami masih mendalami peristiwa tersebut.\r\n",
      "sample:  yang menjadi korban ---- kejadian tersebut tidak timbul korban.\r\n",
      "sample:  kerugian material yang terjadi ---- terjadi kerugian material.\r\n",
      "sample:  di sektor bintaro tangerang selatan, ada yang salah dengan prosedur ---- pembongkaran gedung di sektor 7, bintaro, tangerang selatan, diduga menyalahi prosedur.\r\n",
      "bleu score on test dataset:  9.06008859352565\r\n",
      "evaluate on data d-indo-fuji\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 27\r\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:04<00:00,  1.63it/s]\r\n",
      "sample:  indosat bersama fujitsu indonesia menandatangani nota paham dalam rangka meningkatkan kesuksesan bisnis ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah dibangun dalam menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  indosat bersama fujitsu indonesia menandatangani nota paham dalam rangka meningkatkan kesuksesan bisnis ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah dibangun dalam menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  mobility iot dan tumbuh dengan signifikan pada saat itu ---- smart mobility dan iot mengalami perkembangan cukup signifikan sehingga mengubah cara perusahaan dalam mengelola aset.\r\n",
      "sample:  indosat bersama fujitsu indonesia menandatangani nota paham dalam rangka meningkatkan kesuksesan bisnis ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  di sektor transportasi dan otomotif, kerja sama dilakukan oleh pemerintah dan korporasi indonesia ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "sample:  presiden achmad sofwan menyampaikan manfaat dari teknologi dan teknologi merupakan cara optimal untuk meningkatkan strategi usaha ---- mobilitas akan menyediakan cara untuk mengoptimalkan strategi perusahaan dengan memanfaatkan aplikasi dan layanan yang dapat memproses data real-time, tutur achmad sofwan, president director fujitsu indonesia.\r\n",
      "sample:  di sektor transportasi dan otomotif, kerja sama dilakukan oleh pemerintah dan korporasi indonesia ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "sample:  indosat ooredoo sedang mengerjakan solusi smart mobility dan fujitsu dengan indonesia ---- indosat ooredoo bekerja sama dengan fujitsu indonesia menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  pemerintah achmad sofwan menyampaikan manfaat dari teknologi dan teknologi merupakan cara optimal untuk meningkatkan strategi usaha ---- president director fujitsu, achmad sofwan mengungkap, mobilitas akan menyediakan cara mengoptimalisasikan strategi perusahaan dengan memanfaatkan aplikasi dan layanan dalam aktivitas memproses data real-time.\r\n",
      "sample:  di sektor transportasi dan otomotif, kerja sama dilakukan oleh pemerintah dan korporasi indonesia ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "bleu score on test dataset:  4.194047862982366\r\n",
      "evaluate on data f-bunuh-diri\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 23\r\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.29it/s]\r\n",
      "sample:  di sepanjang jembatan, ia melompat setinggi 15 meter ---- ciptadi dengan nekat melompat dari megatron jembatan penyeberangan orang yang tingginya diperkirakan mencapai 15 meter.\r\n",
      "sample:  hal tersebut diungkapkan oleh kasubag reny marthaliana ---- hal tersebut diungkapkan kabag ops polrestabes bandung kompol dede rojudin didampingi kasubag humas kompol reny marthaliana, saat ditemui di mapolrestabes bandung, jumat.\r\n",
      "sample:  di masjid raya bandung, ia melihat jemaat yang lain ---- rezha noviana, warga kota bandung mengatakan ia dan jemaat lainnya langsung memperhatikan megatron jembatan penyeberangan orang depan kantor pos besar bandung setelah bubar salat jumat di masjid raya bandung.\r\n",
      "sample:  di atas jpo, petugas linmas melakukan tugasnya ---- ketika itu, petugas linmas dan beberapa satpam berdiri di atas jpo.\r\n",
      "sample:  di alun bandung, aksi bunuh diri terjadi ---- aksi bunuh diri di alun - alun bandung belum lama ini terjadi.\r\n",
      "sample:  dirinya terjatuh di alun bandung ---- seorang pria tua nekat menjatuhkan diri dari jpo di alun - alun kota bandung.\r\n",
      "sample:  sudirman menjadi saksi mata di alun bandung ---- sudirman, anggota linmas satpol pp kota bandung yang menjadi saksi mata aksi bunuh diri di alun - alun bandung itu mengatakan, pria tersebut diperkirakan berusia 50 tahun.\r\n",
      "sample:  dirinya terjatuh di pos giro besar bandung pada hari jumat ---- seorang lelaki menjatuhkan diri dari megatron jembatan penyeberangan di depan pos giro besar bandung, bandung, jumat.\r\n",
      "sample:  di tengah padatnya lalu lintas, lelaki itu mengakhiri hidupnya ---- seorang lelaki tengah baya nekat mengakhiri hidupnya di tengah kepadatan lalu lintas jalan asia afrika.\r\n",
      "sample:  di jembatan jalan asia afrika, pria misterius itu membuat pesan belum terjun ke dalam ---- pria misterius yang bunuh diri dari jembatan penyeberangan orang di jalan asia afrika, bandung, jawa barat, membuat pesan sebelum nekat terjun.\r\n",
      "bleu score on test dataset:  6.579701950685511\r\n",
      "evaluate on data g-gempa-dieng\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 19\r\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:03<00:00,  1.64it/s]\r\n",
      "sample:  stasiun banjarnegara jawa tengah mengumumkan gempa yang kuat pada pukul 19. 00 wib ---- stasiun geofisika badan meteorologi klimatologi dan geofisika banjarnegara, jawa tengah, menyatakan bahwa gempa yang mengguncang dataran tinggi dieng pukul 19.00 wib berkekuatan 4,8 pada skala richter.\r\n",
      "sample:  pusat gempa yang ada di desa tanji gugur ---- pusat gempa diperkirakan berada di desa tanji gugur, kecamatan bawang, kabupaten batang.\r\n",
      "sample:  jalan dekat kawah desa sumberejo ditutup sementara ---- pvmbg merekomendasikan seluruh jalan yang mendekati kawah timbang di desa sumberejo sementara ditutup.\r\n",
      "sample:  di dataran tinggi dieng, banyak kejadian terjadi ---- kepala pusat vulkanologi dan mitigasi bencana geologi surono mengatakan bahwa gempa yang terjadi di dataran tinggi dieng pukul 19.00 wib terekam sebanyak 86 kali.\r\n",
      "sample:  di lapangan, tim ukur konsentrasi gas dilakukan tutup ---- penutupan ini dilakukan hingga tim di lapangan yang mengukur konsentrasi gas menyatakan tidak ada gas yang berbahaya.\r\n",
      "sample:  jalan dekat kawah desa sumberejo ditutup sementara ---- pvmbg merekomendasikan seluruh jalan yang mendekati kawah timbang di desa sumberejo sementara ditutup.\r\n",
      "sample:  petugas di pusat vulkanologi mitigasi bencana geologi terjun dan memberikan informasi ---- petugas pusat vulkanologi dan mitigasi bencana geologi diterjunkan untuk memantau aktivitas kawah timbang dan memberikan informasi.\r\n",
      "sample:  data keluar dari pusat vulkanologi mitigasi bencana geologi pada pukul 19.00 wib ---- data yang dikeluarkan dari pusat vulkanologi dan mitigasi bencana geologi menyebutkan gempa mulai terasa pukul 19.00 wib dan telah terekam gempa sebanyak 86 kali.\r\n",
      "sample:  di sabtu pagi, ungsi tersebut ditinggalkan ---- pengungsi di kabupaten banjarnegara, pada sabtu pagi mulai meninggalkan pengungsian.\r\n",
      "sample:  di dataran tinggi dieng, terjadi gempa yang kuat 4 8 skala richter ---- stasiun geofisika badan meteorologi klimatologi dan geofisika banjarnegara menyatakan gempa yang mengguncang dataran tinggi dieng pukul 19.00 wib berkekuatan 4,8 skala richter *(sr)*.\r\n",
      "bleu score on test dataset:  6.618898264836624\r\n"
     ]
    }
   ],
   "source": [
    "!./evaluate_indoT5_to_all.sh result linearized_penman_with_tree_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb4f9c63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T08:25:18.154317Z",
     "iopub.status.busy": "2022-05-18T08:25:18.153512Z",
     "iopub.status.idle": "2022-05-18T08:26:31.927520Z",
     "shell.execute_reply": "2022-05-18T08:26:31.926916Z"
    },
    "papermill": {
     "duration": 77.471198,
     "end_time": "2022-05-18T08:26:31.927656",
     "exception": false,
     "start_time": "2022-05-18T08:25:14.456458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: result/ (stored 0%)\r\n",
      "  adding: result/f-bunuh-diri/ (stored 0%)\r\n",
      "  adding: result/f-bunuh-diri/test_generations.txt (deflated 59%)\r\n",
      "  adding: result/f-bunuh-diri/test_label.txt (deflated 68%)\r\n",
      "  adding: result/f-bunuh-diri/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/amr_simple_test/ (stored 0%)\r\n",
      "  adding: result/amr_simple_test/test_generations.txt (deflated 62%)\r\n",
      "  adding: result/amr_simple_test/test_label.txt (deflated 60%)\r\n",
      "  adding: result/amr_simple_test/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/c-gedung-roboh/ (stored 0%)\r\n",
      "  adding: result/c-gedung-roboh/test_generations.txt (deflated 58%)\r\n",
      "  adding: result/c-gedung-roboh/test_label.txt (deflated 62%)\r\n",
      "  adding: result/c-gedung-roboh/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/d-indo-fuji/ (stored 0%)\r\n",
      "  adding: result/d-indo-fuji/test_generations.txt (deflated 82%)\r\n",
      "  adding: result/d-indo-fuji/test_label.txt (deflated 86%)\r\n",
      "  adding: result/d-indo-fuji/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/test_generations.txt (deflated 62%)\r\n",
      "  adding: result/model/ (stored 0%)\r\n",
      "  adding: result/model/pytorch_model.bin (deflated 11%)\r\n",
      "  adding: result/model/config.json (deflated 45%)\r\n",
      "  adding: result/loss_data.tsv (deflated 36%)\r\n",
      "  adding: result/tokenizer/ (stored 0%)\r\n",
      "  adding: result/tokenizer/tokenizer_config.json (deflated 81%)\r\n",
      "  adding: result/tokenizer/added_tokens.json (deflated 43%)\r\n",
      "  adding: result/tokenizer/special_tokens_map.json (deflated 82%)\r\n",
      "  adding: result/tokenizer/spiece.model (deflated 49%)\r\n",
      "  adding: result/b-salah-darat/ (stored 0%)\r\n",
      "  adding: result/b-salah-darat/test_generations.txt (deflated 61%)\r\n",
      "  adding: result/b-salah-darat/test_label.txt (deflated 66%)\r\n",
      "  adding: result/b-salah-darat/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/test_label.txt (deflated 60%)\r\n",
      "  adding: result/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/g-gempa-dieng/ (stored 0%)\r\n",
      "  adding: result/g-gempa-dieng/test_generations.txt (deflated 59%)\r\n",
      "  adding: result/g-gempa-dieng/test_label.txt (deflated 67%)\r\n",
      "  adding: result/g-gempa-dieng/bleu_score_test.txt (stored 0%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r result_without_sta.zip result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec35a92",
   "metadata": {
    "papermill": {
     "duration": 3.764674,
     "end_time": "2022-05-18T08:26:39.415162",
     "exception": false,
     "start_time": "2022-05-18T08:26:35.650488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Finetune indot5 with linearized penman + supervised task adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a76dd469",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T08:26:47.726851Z",
     "iopub.status.busy": "2022-05-18T08:26:47.726223Z",
     "iopub.status.idle": "2022-05-18T08:26:47.729392Z",
     "shell.execute_reply": "2022-05-18T08:26:47.729790Z"
    },
    "papermill": {
     "duration": 4.27283,
     "end_time": "2022-05-18T08:26:47.729942",
     "exception": false,
     "start_time": "2022-05-18T08:26:43.457112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/amr-to-text-indonesia/train\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/amr-to-text-indonesia/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "548fea7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T08:26:55.482697Z",
     "iopub.status.busy": "2022-05-18T08:26:55.481847Z",
     "iopub.status.idle": "2022-05-18T08:26:56.146758Z",
     "shell.execute_reply": "2022-05-18T08:26:56.146254Z"
    },
    "papermill": {
     "duration": 4.561092,
     "end_time": "2022-05-18T08:26:56.146901",
     "exception": false,
     "start_time": "2022-05-18T08:26:51.585809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'result/model': Is a directory\r\n",
      "rm: cannot remove 'result/tokenizer': Is a directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm result/* -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82daea87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T08:27:03.861545Z",
     "iopub.status.busy": "2022-05-18T08:27:03.860724Z",
     "iopub.status.idle": "2022-05-18T10:19:36.983648Z",
     "shell.execute_reply": "2022-05-18T10:19:36.987845Z"
    },
    "papermill": {
     "duration": 6757.173344,
     "end_time": "2022-05-18T10:19:36.989490",
     "exception": false,
     "start_time": "2022-05-18T08:26:59.816146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing method linearized_penman\r\n",
      "silver data folder ../amr-indo-dataset/data_154k_raw_silver_amr_indo4b_news\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/preprocessed_silver_data/train.amr.txt', result_sent_path='data/preprocessed_silver_data/train.sent.txt', source_file_path=None, source_folder_path='../amr-indo-dataset/data_154k_raw_silver_amr_indo4b_news')\r\n",
      "100%|███████████████████████████████| 269258/269258 [00:01<00:00, 146628.09it/s]\r\n",
      "100%|███████████████████████████████| 270251/270251 [00:01<00:00, 147620.95it/s]\r\n",
      "100%|███████████████████████████████| 268262/268262 [00:01<00:00, 146067.67it/s]\r\n",
      "100%|███████████████████████████████| 264330/264330 [00:02<00:00, 126883.49it/s]\r\n",
      "100%|███████████████████████████████| 264253/264253 [00:02<00:00, 131833.64it/s]\r\n",
      "100%|███████████████████████████████| 263263/263263 [00:01<00:00, 148710.46it/s]\r\n",
      "100%|███████████████████████████████| 266966/266966 [00:02<00:00, 114570.23it/s]\r\n",
      "100%|███████████████████████████████| 268572/268572 [00:01<00:00, 146863.95it/s]\r\n",
      "100%|███████████████████████████████| 265325/265325 [00:01<00:00, 150512.53it/s]\r\n",
      "100%|███████████████████████████████| 263508/263508 [00:02<00:00, 128646.51it/s]\r\n",
      "total: 154892 pair sent-amr\r\n",
      "Running on the GPU\r\n",
      "added 9 tokens\r\n",
      "len train dataset:  154892\r\n",
      "len dev dataset:  19\r\n",
      "len test dataset: 306\r\n",
      "len train dataloader:  38723\r\n",
      "(Epoch 1) TRAIN LOSS:1.2260 LR:0.00003000: 100%|█| 38723/38723 [1:51:22<00:00,  \r\n",
      "(Epoch 1) DEV LOSS:2.6037 LR:0.00003000: 100%|████| 5/5 [00:00<00:00, 30.35it/s]\r\n",
      "bleu score on dev:  22.235845625253816\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:22<00:00,  3.49it/s]\r\n",
      "sample:  ilham meniup balon. ---- balon itu ditiup ilham\r\n",
      "sample:  obe menulis puisi. ---- obe menulis puisi\r\n",
      "sample:  saya mengetik makalah itu. ---- saya mengetik makalah\r\n",
      "sample:  angga, anak ajaib. ---- angga anak ajaib\r\n",
      "sample:  ibu saya orang dosen. ---- ibuku seorang dosen\r\n",
      "bleu score on test dataset:  36.27318802140039\r\n",
      "saya mengetik makalah itu.\r\n"
     ]
    }
   ],
   "source": [
    "!chmod +x train_indoT5_on_silver_data.sh\n",
    "!./train_indoT5_on_silver_data.sh linearized_penman ../amr-indo-dataset/data_154k_raw_silver_amr_indo4b_news 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a174dec6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:20:23.656523Z",
     "iopub.status.busy": "2022-05-18T10:20:23.655758Z",
     "iopub.status.idle": "2022-05-18T10:20:24.328726Z",
     "shell.execute_reply": "2022-05-18T10:20:24.328211Z"
    },
    "papermill": {
     "duration": 23.732594,
     "end_time": "2022-05-18T10:20:24.328858",
     "exception": false,
     "start_time": "2022-05-18T10:20:00.596264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu_score_test.txt  model\t\t   test_label.txt\r\n",
      "loss_data.tsv\t     test_generations.txt  tokenizer\r\n"
     ]
    }
   ],
   "source": [
    "!ls result/result_supervised_task_adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e8bf701",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:21:10.440540Z",
     "iopub.status.busy": "2022-05-18T10:21:10.439742Z",
     "iopub.status.idle": "2022-05-18T10:21:11.096194Z",
     "shell.execute_reply": "2022-05-18T10:21:11.095480Z"
    },
    "papermill": {
     "duration": 23.361329,
     "end_time": "2022-05-18T10:21:11.096332",
     "exception": false,
     "start_time": "2022-05-18T10:20:47.735003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir result/result_linearized_penman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "546b012a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:21:56.983823Z",
     "iopub.status.busy": "2022-05-18T10:21:56.983068Z",
     "iopub.status.idle": "2022-05-18T10:25:15.400076Z",
     "shell.execute_reply": "2022-05-18T10:25:15.399549Z"
    },
    "papermill": {
     "duration": 221.40411,
     "end_time": "2022-05-18T10:25:15.400220",
     "exception": false,
     "start_time": "2022-05-18T10:21:33.996110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\r\n",
      "resume from checkpoint\r\n",
      "added 0 tokens\r\n",
      "len train dataset:  2648\r\n",
      "len dev dataset:  19\r\n",
      "len test dataset: 306\r\n",
      "len train dataloader:  662\r\n",
      "(Epoch 1) TRAIN LOSS:1.0876 LR:0.00010000: 100%|█| 662/662 [01:22<00:00,  8.06it\r\n",
      "(Epoch 1) DEV LOSS:0.9416 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 30.66it/s]\r\n",
      "bleu score on dev:  27.581071881605936\r\n",
      "(Epoch 2) TRAIN LOSS:0.7821 LR:0.00010000: 100%|█| 662/662 [01:21<00:00,  8.12it\r\n",
      "(Epoch 2) DEV LOSS:0.8086 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 32.96it/s]\r\n",
      "bleu score on dev:  32.472333257469664\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:16<00:00,  4.70it/s]\r\n",
      "sample:  balon ditiup ilham ---- balon itu ditiup ilham\r\n",
      "sample:  puisi ditulis obe ---- obe menulis puisi\r\n",
      "sample:  saya mengetik makalah ---- saya mengetik makalah\r\n",
      "sample:  angga anak ajaib ---- angga anak ajaib\r\n",
      "sample:  ibu seorang dosen ---- ibuku seorang dosen\r\n",
      "bleu score on test dataset:  47.88202674843841\r\n",
      "saya mengetik makalah\r\n"
     ]
    }
   ],
   "source": [
    "!python train_indoT5.py --model_type indo-t5 --n_epochs 2 --lr 0.0001 --data_folder ../data/preprocessed_data/linearized_penman  --result_folder result/result_linearized_penman --resume_from_checkpoint True --saved_model_folder_path result/result_supervised_task_adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75247785",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:26:03.344504Z",
     "iopub.status.busy": "2022-05-18T10:26:03.343722Z",
     "iopub.status.idle": "2022-05-18T10:27:02.800568Z",
     "shell.execute_reply": "2022-05-18T10:27:02.800122Z"
    },
    "papermill": {
     "duration": 84.245117,
     "end_time": "2022-05-18T10:27:02.800739",
     "exception": false,
     "start_time": "2022-05-18T10:25:38.555622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: result/result_linearized_penman/ (stored 0%)\r\n",
      "  adding: result/result_linearized_penman/test_generations.txt (deflated 63%)\r\n",
      "  adding: result/result_linearized_penman/model/ (stored 0%)\r\n",
      "  adding: result/result_linearized_penman/model/pytorch_model.bin (deflated 9%)\r\n",
      "  adding: result/result_linearized_penman/model/config.json (deflated 45%)\r\n",
      "  adding: result/result_linearized_penman/loss_data.tsv (deflated 18%)\r\n",
      "  adding: result/result_linearized_penman/tokenizer/ (stored 0%)\r\n",
      "  adding: result/result_linearized_penman/tokenizer/tokenizer_config.json (deflated 81%)\r\n",
      "  adding: result/result_linearized_penman/tokenizer/added_tokens.json (deflated 43%)\r\n",
      "  adding: result/result_linearized_penman/tokenizer/special_tokens_map.json (deflated 83%)\r\n",
      "  adding: result/result_linearized_penman/tokenizer/spiece.model (deflated 49%)\r\n",
      "  adding: result/result_linearized_penman/test_label.txt (deflated 60%)\r\n",
      "  adding: result/result_linearized_penman/bleu_score_test.txt (stored 0%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r result_with_sta.zip result/result_linearized_penman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "566f889b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:27:50.359644Z",
     "iopub.status.busy": "2022-05-18T10:27:50.359097Z",
     "iopub.status.idle": "2022-05-18T10:27:50.370611Z",
     "shell.execute_reply": "2022-05-18T10:27:50.370167Z"
    },
    "papermill": {
     "duration": 23.277258,
     "end_time": "2022-05-18T10:27:50.370757",
     "exception": false,
     "start_time": "2022-05-18T10:27:27.093499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/amr-to-text-indonesia/evaluate\n"
     ]
    }
   ],
   "source": [
    "%cd ../evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54cee71a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:28:37.834381Z",
     "iopub.status.busy": "2022-05-18T10:28:37.832792Z",
     "iopub.status.idle": "2022-05-18T10:28:38.482715Z",
     "shell.execute_reply": "2022-05-18T10:28:38.482156Z"
    },
    "papermill": {
     "duration": 24.271805,
     "end_time": "2022-05-18T10:28:38.482853",
     "exception": false,
     "start_time": "2022-05-18T10:28:14.211048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'result/amr_simple_test': Is a directory\r\n",
      "rm: cannot remove 'result/b-salah-darat': Is a directory\r\n",
      "rm: cannot remove 'result/c-gedung-roboh': Is a directory\r\n",
      "rm: cannot remove 'result/d-indo-fuji': Is a directory\r\n",
      "rm: cannot remove 'result/f-bunuh-diri': Is a directory\r\n",
      "rm: cannot remove 'result/g-gempa-dieng': Is a directory\r\n",
      "rm: cannot remove 'result/linearized_penman': Is a directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm result/* -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fc1c296",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:29:25.649313Z",
     "iopub.status.busy": "2022-05-18T10:29:25.648479Z",
     "iopub.status.idle": "2022-05-18T10:31:26.535602Z",
     "shell.execute_reply": "2022-05-18T10:31:26.535136Z"
    },
    "papermill": {
     "duration": 143.979419,
     "end_time": "2022-05-18T10:31:26.535788",
     "exception": false,
     "start_time": "2022-05-18T10:29:02.556369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model folder ../train/result/result_linearized_penman\r\n",
      "preprocessing method linearized_penman\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data’: File exists\r\n",
      "preprocess amr_simple_test\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/amr_simple_test’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/amr_simple_test/test.amr.txt', result_sent_path='data/test/preprocessed_data/amr_simple_test/test.sent.txt', source_file_path='data/test/amr_simple_test.txt', source_folder_path=None)\r\n",
      "100%|███████████████████████████████████| 2618/2618 [00:00<00:00, 183338.42it/s]\r\n",
      "total: 306 pair sent-amr\r\n",
      "preprocess b-salah-darat\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/b-salah-darat’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/b-salah-darat/test.amr.txt', result_sent_path='data/test/preprocessed_data/b-salah-darat/test.sent.txt', source_file_path='data/test/b-salah-darat.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 676/676 [00:00<00:00, 116955.39it/s]\r\n",
      "total: 32 pair sent-amr\r\n",
      "preprocess c-gedung-roboh\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/c-gedung-roboh’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/c-gedung-roboh/test.amr.txt', result_sent_path='data/test/preprocessed_data/c-gedung-roboh/test.sent.txt', source_file_path='data/test/c-gedung-roboh.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 606/606 [00:00<00:00, 128261.00it/s]\r\n",
      "total: 29 pair sent-amr\r\n",
      "preprocess d-indo-fuji\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/d-indo-fuji’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/d-indo-fuji/test.amr.txt', result_sent_path='data/test/preprocessed_data/d-indo-fuji/test.sent.txt', source_file_path='data/test/d-indo-fuji.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 745/745 [00:00<00:00, 110434.93it/s]\r\n",
      "total: 27 pair sent-amr\r\n",
      "preprocess f-bunuh-diri\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/f-bunuh-diri’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/f-bunuh-diri/test.amr.txt', result_sent_path='data/test/preprocessed_data/f-bunuh-diri/test.sent.txt', source_file_path='data/test/f-bunuh-diri.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 468/468 [00:00<00:00, 133107.36it/s]\r\n",
      "total: 23 pair sent-amr\r\n",
      "preprocess g-gempa-dieng\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/g-gempa-dieng’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/g-gempa-dieng/test.amr.txt', result_sent_path='data/test/preprocessed_data/g-gempa-dieng/test.sent.txt', source_file_path='data/test/g-gempa-dieng.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 412/412 [00:00<00:00, 130379.75it/s]\r\n",
      "total: 19 pair sent-amr\r\n",
      "mkdir: cannot create directory ‘result’: File exists\r\n",
      "evaluate on data amr_simple_test\r\n",
      "mkdir: cannot create directory ‘result/amr_simple_test’: File exists\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/result_linearized_penman/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/result_linearized_penman/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 306\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:15<00:00,  4.82it/s]\r\n",
      "sample:  balon ditiup ilham ---- balon itu ditiup ilham\r\n",
      "sample:  puisi ditulis obe ---- obe menulis puisi\r\n",
      "sample:  saya mengetik makalah ---- saya mengetik makalah\r\n",
      "sample:  angga anak ajaib ---- angga anak ajaib\r\n",
      "sample:  ibu seorang dosen ---- ibuku seorang dosen\r\n",
      "sample:  dia sedang berenang ---- dia sedang berenang\r\n",
      "sample:  buku yang hilang dicari ilham ---- ilham sedang mencari bukunya yang hilang\r\n",
      "sample:  ibu menyapu halaman rumah ---- ibu sedang menyapu halaman rumah\r\n",
      "sample:  padi di sawah dibajak ayah ---- ayah sedang membajak padi di sawah\r\n",
      "sample:  andi pergi kemah di tepi pantai ---- andi pergi berkemah di tepi pantai\r\n",
      "bleu score on test dataset:  47.88202674843841\r\n",
      "evaluate on data b-salah-darat\r\n",
      "mkdir: cannot create directory ‘result/b-salah-darat’: File exists\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/result_linearized_penman/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/result_linearized_penman/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 32\r\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:05<00:00,  1.54it/s]\r\n",
      "sample:  kantor kerja sama pt angkasa pura ii dan otoritas bandara soekarno-hatta membahas insiden penumpang terbang pesawat tiba dari jakarta pada 10 mei 2016 ---- kantor imigrasi bandara soekarno-hatta bersama kantor otoritas bandara soekarno-hatta dan pt angkasa pura ii membahas insiden penumpang penerbangan pesawat lion air jt 161 yang tiba di jakarta dari singapura 10 mei 2016.\r\n",
      "sample:  kepala kantor imigrasi soekarnohatta alif suadi mengatakan kepada tempo sabtu malam ini 14 mei 2016 ---- kami meeting soal ini,\" ujar kepala kantor imigrasi soekarno-hatta alif suadi kepada tempo, sabtu malam ini, 14 mei 2016.\r\n",
      "sample:  anak temannya natalie berangkat dan menggunakan pesawat lion air jt 161 pukul 18 55 ke singapura ---- anak temannya natalie berangkat dari singapura dan menggunakan pesawat lion air jt 161, pada pukul 18.50.\r\n",
      "sample:  sekretaris agus haryadi mengatakan perusahaan pt angkasa pura ii akan melakukan koordinasi dengan kantor otoritas bandara wilayah 1 terkait dengan perisitiwa ---- sekretaris perusahaan pt angkasa pura ii agus haryadi mengatakan selaku pengelola bandara internasional soekarno-hatta, pihaknya akan berkoordinasi dengan kantor otoritas bandara wilayah i terkait dengan peristiwa ini.\r\n",
      "sample:  di remote area, kami menyiapkan bus antar penumpang ke terminal ---- setiap pesawat yang parkir di remote area sudah kami siapkan bus untuk mengantar penumpang ke terminal.\r\n",
      "sample:  edward menuturkan dapat mendapatkan sopir penjemput penumpang dari padang dengan bus ---- terdapat sopir bus yang akan menjemput penumpang dari padang\" ujar edward.\r\n",
      "sample:  pihak otoritas bandara soetta memanggil pihak terkait dan pelaku investigasi melakukan investigasi ---- pihak otoritas bandara soetta akan memanggil pihak terkait dan dilakukan investigasi.\r\n",
      "sample:  kemenhub memberikan sanksi kepada pihak-pihak yang lalai ---- kemenhub memberikan sanksi kepada pihak-pihak yang lalai,\" ujarnya.\r\n",
      "sample:  zara mengutip cerita temannya, pesawat itu tidak mendarat di terminal ii ---- pesawat itu mendarat tidak di terminal ii, kata zara mengutip cerita temannya.\r\n",
      "sample:  di remote area, kami menyiapkan bus antar penumpang ke terminal ---- setiap pesawat yang parkir di remote area sudah kami siapkan bus untuk mengantar penumpang ke terminal.\r\n",
      "bleu score on test dataset:  21.719965225457745\r\n",
      "evaluate on data c-gedung-roboh\r\n",
      "mkdir: cannot create directory ‘result/c-gedung-roboh’: File exists\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/result_linearized_penman/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/result_linearized_penman/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 29\r\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:04<00:00,  1.67it/s]\r\n",
      "sample:  kendaraan laju arah mal bintaro xchange dan tol bintaro menuju jalan boulevard bintaro dilakukan alih dengan menggunakan flyover di atas lampu indomobil merah ---- pengalihan dilakukan bagi pengendara yang melaju dari arah mal bintaro xchange dan tol bintaro menuju jalan boulevard bintaro dengan menggunakan flyover di atas lampu merah indomobil.\r\n",
      "sample:  dia mengakibatkan kegagalan dan kesalahan tes tanah terjadi di menara jalan jakarta timur mt haryono dan saidah ---- kegagalan struktur dan kesalahan tes tanah yang mengakibatkan gedung miring juga terjadi pada menara saidah di jalan mt haryono, jakarta timur.\r\n",
      "sample:  kapolres ayi supardan di tangerang selatan membenarkan peristiwa bintaro roboh gedung itu menarik hati masyarakat banyak ---- kapolres tangerang selatan, akbp ayi supardan membenarkan peristiwa robohnya gedung di bintaro yang menarik perhatian masyarakat banyak.\r\n",
      "sample:  pembangunan gedung diputuskan oleh panin karena dinyatakan tidak lulus ujian kelayakan ---- panin memutuskan tidak melanjutkan pembangunan gedung itu karena dinyatakan tidak lulus uji kelayakan.\r\n",
      "sample:  gedung tersebut dinyatakan tidak lulus ujian sehingga bangunan tersebut memutuskan untuk tidak melanjutkan ke gedung ---- gedung tersebut dinyatakan tidak lulus uji sehingga pembangunan gedung diputuskan tidak dilanjutkan.\r\n",
      "sample:  kasat akp samian di polres tangerang selatan mengatakan reskrim sedang melakukan penyelidikan untuk mengetahui penyebab keruntuhan gedung saat ini ---- kasat reskrim polres tangerangg selatan, akp samian mengatakan saat ini pihaknya melakukan penyelidikan untuk mengetahui penyebab runtuhnya gedung.\r\n",
      "sample:  kami masih dalam peristiwa yang disebut hingga ini ---- hingga kini kami masih mendalami peristiwa tersebut.\r\n",
      "sample:  kejadian tersebut tidak menimbulkan korban ---- kejadian tersebut tidak timbul korban.\r\n",
      "sample:  kerugian material terjadi ---- terjadi kerugian material.\r\n",
      "sample:  di sektor bintaro, tangerang selatan, 7 gedung dibongkar karena kesalahan prosedur ---- pembongkaran gedung di sektor 7, bintaro, tangerang selatan, diduga menyalahi prosedur.\r\n",
      "bleu score on test dataset:  25.82629083337038\r\n",
      "evaluate on data d-indo-fuji\r\n",
      "mkdir: cannot create directory ‘result/d-indo-fuji’: File exists\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/result_linearized_penman/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/result_linearized_penman/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 27\r\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:05<00:00,  1.19it/s]\r\n",
      "sample:  indosat dengan fujitsu indonesia menandatangani nota pemahaman dalam rangka memantapkan mitra pembangunan yang telah menghadirkan solusi smart dan internet of things untuk mobility ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah dibangun dalam menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  indosat dengan fujitsu indonesia menandatangani nota pemahaman dalam rangka memantapkan mitra pembangunan yang telah menghadirkan solusi smart dan internet of things untuk mobility ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah dibangun dalam menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  smart mobility dan iot mengalami perkembangan yang cukup signifikan hingga cara perusahaan mengelola aset berubah ---- smart mobility dan iot mengalami perkembangan cukup signifikan sehingga mengubah cara perusahaan dalam mengelola aset.\r\n",
      "sample:  indosat dengan fujitsu indonesia menandatangani nota pemahaman dalam rangka memantapkan mitra pembangunan yang telah menghadirkan solusi smart dan internet of things untuk mobility ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  kerja sama difokuskan pada sektor transportasi dan otomotif yang luas untuk memenuhi kebutuhan pelanggan korporasi di indonesia ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "sample:  president achmad sofwan, president director fujitsu indonesia, menuturkan penyediaan layanan proses data real-time dan mobilitas merupakan cara yang optimal untuk mengoptimalkan strategi perusahaan ---- mobilitas akan menyediakan cara untuk mengoptimalkan strategi perusahaan dengan memanfaatkan aplikasi dan layanan yang dapat memproses data real-time, tutur achmad sofwan, president director fujitsu indonesia.\r\n",
      "sample:  kerja sama difokuskan pada sektor transportasi dan otomotif yang luas untuk memenuhi kebutuhan pelanggan korporasi di indonesia ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "sample:  indosat ooredoo mengerjakan solusi smart mobility dan internet of things bekerja sama dengan fujitsu di indonesia ---- indosat ooredoo bekerja sama dengan fujitsu indonesia menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  president achmad sofwan, president director fujitsu mengungkapkan ketersediaan layanan proses data real-time dan mobilitas merupakan cara optimal untuk mengoptimalkan strategi perusahaan ---- president director fujitsu, achmad sofwan mengungkap, mobilitas akan menyediakan cara mengoptimalisasikan strategi perusahaan dengan memanfaatkan aplikasi dan layanan dalam aktivitas memproses data real-time.\r\n",
      "sample:  kerja sama difokuskan pada sektor transportasi dan otomotif yang luas untuk memenuhi kebutuhan pelanggan korporasi di indonesia ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "bleu score on test dataset:  22.07323388947666\r\n",
      "evaluate on data f-bunuh-diri\r\n",
      "mkdir: cannot create directory ‘result/f-bunuh-diri’: File exists\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/result_linearized_penman/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/result_linearized_penman/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 23\r\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:04<00:00,  1.40it/s]\r\n",
      "sample:  ciptadi melompat dari megatron jembatan yang tingginya diperkirakan mencapai 15 meter ---- ciptadi dengan nekat melompat dari megatron jembatan penyeberangan orang yang tingginya diperkirakan mencapai 15 meter.\r\n",
      "sample:  hal yang disebut diungkapkan oleh kasubag reny marthaliana, kabag humas kompol, kabag dede rojudin, ops polrestabes bandung, jumat di mapolrestabes bandung ---- hal tersebut diungkapkan kabag ops polrestabes bandung kompol dede rojudin didampingi kasubag humas kompol reny marthaliana, saat ditemui di mapolrestabes bandung, jumat.\r\n",
      "sample:  rezha warga kota bandung noviana mengatakan ia telah membubarkan salat di masjid raya bandung jumat ini dan jemaat lainnya memperhatikan megatron di depan kantor bandung ---- rezha noviana, warga kota bandung mengatakan ia dan jemaat lainnya langsung memperhatikan megatron jembatan penyeberangan orang depan kantor pos besar bandung setelah bubar salat jumat di masjid raya bandung.\r\n",
      "sample:  di atas jpo, petugas linmas berdiri ---- ketika itu, petugas linmas dan beberapa satpam berdiri di atas jpo.\r\n",
      "sample:  aksi bunuh diri terjadi di alun bandung belum lama ini ---- aksi bunuh diri di alun - alun bandung belum lama ini terjadi.\r\n",
      "sample:  orang pria tua itu terjatuh dari jpo di alun kota bandung di alun ---- seorang pria tua nekat menjatuhkan diri dari jpo di alun - alun kota bandung.\r\n",
      "sample:  sudirman menjadi saksi mata pembunuhan di alun bandung, satpol pp mengatakan, pria itu diperkirakan berusia 30 tahun ---- sudirman, anggota linmas satpol pp kota bandung yang menjadi saksi mata aksi bunuh diri di alun - alun bandung itu mengatakan, pria tersebut diperkirakan berusia 50 tahun.\r\n",
      "sample:  lelaki itu terjatuh dari megatron depan bandung di pos giro besar bandung di jembatan seberang, jumat ---- seorang lelaki menjatuhkan diri dari megatron jembatan penyeberangan di depan pos giro besar bandung, bandung, jumat.\r\n",
      "sample:  lelaki tengah baya mengakhiri hidupnya di tengah padatnya lalu lintas ---- seorang lelaki tengah baya nekat mengakhiri hidupnya di tengah kepadatan lalu lintas jalan asia afrika.\r\n",
      "sample:  di jembatan jalan bandung jawa barat asia afrika di seberang orang membuat pesan belum terjun secara nekat ---- pria misterius yang bunuh diri dari jembatan penyeberangan orang di jalan asia afrika, bandung, jawa barat, membuat pesan sebelum nekat terjun.\r\n",
      "bleu score on test dataset:  20.780335882676734\r\n",
      "evaluate on data g-gempa-dieng\r\n",
      "mkdir: cannot create directory ‘result/g-gempa-dieng’: File exists\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/result_linearized_penman/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/result_linearized_penman/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 19\r\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:03<00:00,  1.41it/s]\r\n",
      "sample:  stasiun banjarnegara, jawa tengah, badan meteorologi klimatologi geofisika menyatakan gempa berkekuatan 4 8 skala richter mengguncang dataran tinggi dieng pada pukul 19 00 wib ---- stasiun geofisika badan meteorologi klimatologi dan geofisika banjarnegara, jawa tengah, menyatakan bahwa gempa yang mengguncang dataran tinggi dieng pukul 19.00 wib berkekuatan 4,8 pada skala richter.\r\n",
      "sample:  pusat gempa diperkirakan ada di desa kecamatan kabupaten batang, tanji gugur ---- pusat gempa diperkirakan berada di desa tanji gugur, kecamatan bawang, kabupaten batang.\r\n",
      "sample:  jalan dekat kawah desa sumberejo ditutup sementara oleh pvmbg secara menyeluruh ---- pvmbg merekomendasikan seluruh jalan yang mendekati kawah timbang di desa sumberejo sementara ditutup.\r\n",
      "sample:  kepala surono di pusat vulkanologi mitigasi bencana geologi mengatakan sebanyak 86 kali gempa terjadi pada pukul 19 00 wib di dataran tinggi dieng ---- kepala pusat vulkanologi dan mitigasi bencana geologi surono mengatakan bahwa gempa yang terjadi di dataran tinggi dieng pukul 19.00 wib terekam sebanyak 86 kali.\r\n",
      "sample:  tutup dilakukan hingga tim ukur konsentrasi gas di lapangan, dinyatakan tidak ada gas berbahaya ---- penutupan ini dilakukan hingga tim di lapangan yang mengukur konsentrasi gas menyatakan tidak ada gas yang berbahaya.\r\n",
      "sample:  jalan dekat kawah desa sumberejo ditutup sementara oleh pvmbg secara menyeluruh ---- pvmbg merekomendasikan seluruh jalan yang mendekati kawah timbang di desa sumberejo sementara ditutup.\r\n",
      "sample:  petugas pusat vulkanologi mitigasi bencana geologi terjun-01 untuk memantau aktivitas kawah yang ditimbang dan memberikan informasi ---- petugas pusat vulkanologi dan mitigasi bencana geologi diterjunkan untuk memantau aktivitas kawah timbang dan memberikan informasi.\r\n",
      "sample:  data yang dikeluarkan oleh pusat vulkanologi mitigasi bencana geologi disebutkan sebanyak 86 kali dan gempa mulai pukul 19 00 wib ---- data yang dikeluarkan dari pusat vulkanologi dan mitigasi bencana geologi menyebutkan gempa mulai terasa pukul 19.00 wib dan telah terekam gempa sebanyak 86 kali.\r\n",
      "sample:  di kabupaten banjarnegara, pengungsi meninggal sabtu pagi ---- pengungsi di kabupaten banjarnegara, pada sabtu pagi mulai meninggalkan pengungsian.\r\n",
      "sample:  stasiun banjarnegara, badan meteorologi klimatologi geofisika menyatakan gempa berkekuatan 4 8 skala richter mengguncang dataran tinggi dieng pada pukul 19 00 wib ---- stasiun geofisika badan meteorologi klimatologi dan geofisika banjarnegara menyatakan gempa yang mengguncang dataran tinggi dieng pukul 19.00 wib berkekuatan 4,8 skala richter *(sr)*.\r\n",
      "bleu score on test dataset:  24.4159297293783\r\n",
      "mkdir: cannot create directory ‘result/linearized_penman’: File exists\r\n",
      "mv: cannot move 'result/amr_simple_test' to 'result/linearized_penman/amr_simple_test': Directory not empty\r\n",
      "mv: cannot move 'result/b-salah-darat' to 'result/linearized_penman/b-salah-darat': Directory not empty\r\n",
      "mv: cannot move 'result/c-gedung-roboh' to 'result/linearized_penman/c-gedung-roboh': Directory not empty\r\n",
      "mv: cannot move 'result/d-indo-fuji' to 'result/linearized_penman/d-indo-fuji': Directory not empty\r\n",
      "mv: cannot move 'result/f-bunuh-diri' to 'result/linearized_penman/f-bunuh-diri': Directory not empty\r\n",
      "mv: cannot move 'result/g-gempa-dieng' to 'result/linearized_penman/g-gempa-dieng': Directory not empty\r\n",
      "mv: cannot move 'result/linearized_penman' to a subdirectory of itself, 'result/linearized_penman/linearized_penman'\r\n"
     ]
    }
   ],
   "source": [
    "!./evaluate_indoT5_to_all.sh ../train/result/result_linearized_penman linearized_penman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4472a9c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:32:13.538335Z",
     "iopub.status.busy": "2022-05-18T10:32:13.537542Z",
     "iopub.status.idle": "2022-05-18T10:32:14.196927Z",
     "shell.execute_reply": "2022-05-18T10:32:14.196430Z"
    },
    "papermill": {
     "duration": 23.767764,
     "end_time": "2022-05-18T10:32:14.197062",
     "exception": false,
     "start_time": "2022-05-18T10:31:50.429298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: result/ (stored 0%)\r\n",
      "  adding: result/f-bunuh-diri/ (stored 0%)\r\n",
      "  adding: result/f-bunuh-diri/test_generations.txt (deflated 63%)\r\n",
      "  adding: result/f-bunuh-diri/test_label.txt (deflated 68%)\r\n",
      "  adding: result/f-bunuh-diri/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/amr_simple_test/ (stored 0%)\r\n",
      "  adding: result/amr_simple_test/test_generations.txt (deflated 63%)\r\n",
      "  adding: result/amr_simple_test/test_label.txt (deflated 60%)\r\n",
      "  adding: result/amr_simple_test/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/c-gedung-roboh/ (stored 0%)\r\n",
      "  adding: result/c-gedung-roboh/test_generations.txt (deflated 62%)\r\n",
      "  adding: result/c-gedung-roboh/test_label.txt (deflated 62%)\r\n",
      "  adding: result/c-gedung-roboh/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/d-indo-fuji/ (stored 0%)\r\n",
      "  adding: result/d-indo-fuji/test_generations.txt (deflated 85%)\r\n",
      "  adding: result/d-indo-fuji/test_label.txt (deflated 86%)\r\n",
      "  adding: result/d-indo-fuji/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/f-bunuh-diri/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/f-bunuh-diri/test_generations.txt (deflated 65%)\r\n",
      "  adding: result/linearized_penman/f-bunuh-diri/test_label.txt (deflated 68%)\r\n",
      "  adding: result/linearized_penman/f-bunuh-diri/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/amr_simple_test/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/amr_simple_test/test_generations.txt (deflated 62%)\r\n",
      "  adding: result/linearized_penman/amr_simple_test/test_label.txt (deflated 60%)\r\n",
      "  adding: result/linearized_penman/amr_simple_test/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/c-gedung-roboh/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/c-gedung-roboh/test_generations.txt (deflated 62%)\r\n",
      "  adding: result/linearized_penman/c-gedung-roboh/test_label.txt (deflated 62%)\r\n",
      "  adding: result/linearized_penman/c-gedung-roboh/bleu_score_test.txt (deflated 12%)\r\n",
      "  adding: result/linearized_penman/d-indo-fuji/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/d-indo-fuji/test_generations.txt (deflated 86%)\r\n",
      "  adding: result/linearized_penman/d-indo-fuji/test_label.txt (deflated 86%)\r\n",
      "  adding: result/linearized_penman/d-indo-fuji/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/b-salah-darat/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/b-salah-darat/test_generations.txt (deflated 66%)\r\n",
      "  adding: result/linearized_penman/b-salah-darat/test_label.txt (deflated 66%)\r\n",
      "  adding: result/linearized_penman/b-salah-darat/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/g-gempa-dieng/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/g-gempa-dieng/test_generations.txt (deflated 66%)\r\n",
      "  adding: result/linearized_penman/g-gempa-dieng/test_label.txt (deflated 67%)\r\n",
      "  adding: result/linearized_penman/g-gempa-dieng/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/b-salah-darat/ (stored 0%)\r\n",
      "  adding: result/b-salah-darat/test_generations.txt (deflated 63%)\r\n",
      "  adding: result/b-salah-darat/test_label.txt (deflated 66%)\r\n",
      "  adding: result/b-salah-darat/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/g-gempa-dieng/ (stored 0%)\r\n",
      "  adding: result/g-gempa-dieng/test_generations.txt (deflated 64%)\r\n",
      "  adding: result/g-gempa-dieng/test_label.txt (deflated 67%)\r\n",
      "  adding: result/g-gempa-dieng/bleu_score_test.txt (stored 0%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r result_with_sta.zip result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db843b19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:33:02.221449Z",
     "iopub.status.busy": "2022-05-18T10:33:02.220585Z",
     "iopub.status.idle": "2022-05-18T10:33:02.874536Z",
     "shell.execute_reply": "2022-05-18T10:33:02.875090Z"
    },
    "papermill": {
     "duration": 24.599505,
     "end_time": "2022-05-18T10:33:02.875261",
     "exception": false,
     "start_time": "2022-05-18T10:32:38.275756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate_indoBART.py\t     result_without_sta.zip\r\n",
      "evaluate_indoBART_to_all.sh  zeroshot_evaluate_indoBART.py\r\n",
      "evaluate_indoT5.py\t     zeroshot_evaluate_indoBART_to_all.sh\r\n",
      "evaluate_indoT5_to_all.sh    zeroshot_evaluate_indoT5.py\r\n",
      "result\t\t\t     zeroshot_evaluate_indoT5_to_all.sh\r\n",
      "result_with_sta.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239bbf75",
   "metadata": {
    "papermill": {
     "duration": 23.977002,
     "end_time": "2022-05-18T10:33:49.919484",
     "exception": false,
     "start_time": "2022-05-18T10:33:25.942482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## linearized penman + tree level embeddings + supervised task adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72e9f25d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:34:37.299764Z",
     "iopub.status.busy": "2022-05-18T10:34:37.298949Z",
     "iopub.status.idle": "2022-05-18T10:34:37.302377Z",
     "shell.execute_reply": "2022-05-18T10:34:37.302989Z"
    },
    "papermill": {
     "duration": 23.351292,
     "end_time": "2022-05-18T10:34:37.303177",
     "exception": false,
     "start_time": "2022-05-18T10:34:13.951885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/amr-to-text-indonesia/tree_level_embeddings\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/amr-to-text-indonesia/tree_level_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef53baef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:35:25.198428Z",
     "iopub.status.busy": "2022-05-18T10:35:25.197638Z",
     "iopub.status.idle": "2022-05-18T10:35:25.851327Z",
     "shell.execute_reply": "2022-05-18T10:35:25.852135Z"
    },
    "papermill": {
     "duration": 24.460002,
     "end_time": "2022-05-18T10:35:25.852315",
     "exception": false,
     "start_time": "2022-05-18T10:35:01.392313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'result/amr_simple_test': Is a directory\r\n",
      "rm: cannot remove 'result/b-salah-darat': Is a directory\r\n",
      "rm: cannot remove 'result/c-gedung-roboh': Is a directory\r\n",
      "rm: cannot remove 'result/d-indo-fuji': Is a directory\r\n",
      "rm: cannot remove 'result/f-bunuh-diri': Is a directory\r\n",
      "rm: cannot remove 'result/g-gempa-dieng': Is a directory\r\n",
      "rm: cannot remove 'result/model': Is a directory\r\n",
      "rm: cannot remove 'result/tokenizer': Is a directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm result/* -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85b2fde5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:36:13.117479Z",
     "iopub.status.busy": "2022-05-18T10:36:13.116617Z",
     "iopub.status.idle": "2022-05-18T12:29:45.440435Z",
     "shell.execute_reply": "2022-05-18T12:29:45.424427Z"
    },
    "papermill": {
     "duration": 6836.192214,
     "end_time": "2022-05-18T12:29:45.440560",
     "exception": false,
     "start_time": "2022-05-18T10:35:49.248346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing method linearized_penman_with_tree_level\r\n",
      "silver data folder ../amr-indo-dataset/data_154k_raw_silver_amr_indo4b_news\r\n",
      "mkdir: cannot create directory ‘data/preprocessed_silver_data’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/preprocessed_silver_data/train.amr.txt', result_sent_path='data/preprocessed_silver_data/train.sent.txt', source_file_path=None, source_folder_path='../amr-indo-dataset/data_154k_raw_silver_amr_indo4b_news')\r\n",
      "100%|███████████████████████████████| 269258/269258 [00:01<00:00, 147274.27it/s]\r\n",
      "15062\r\n",
      "100%|███████████████████████████████| 270251/270251 [00:01<00:00, 146123.38it/s]\r\n",
      "14986\r\n",
      "100%|███████████████████████████████| 268262/268262 [00:01<00:00, 140719.25it/s]\r\n",
      "14991\r\n",
      "100%|███████████████████████████████| 264330/264330 [00:02<00:00, 115103.29it/s]\r\n",
      "15942\r\n",
      "100%|███████████████████████████████| 264253/264253 [00:01<00:00, 139141.91it/s]\r\n",
      "16046\r\n",
      "100%|███████████████████████████████| 263263/263263 [00:01<00:00, 142778.63it/s]\r\n",
      "15995\r\n",
      "100%|███████████████████████████████| 266966/266966 [00:01<00:00, 146023.66it/s]\r\n",
      "14930\r\n",
      "100%|███████████████████████████████| 268572/268572 [00:02<00:00, 130871.57it/s]\r\n",
      "14937\r\n",
      "100%|███████████████████████████████| 265325/265325 [00:01<00:00, 148007.59it/s]\r\n",
      "16077\r\n",
      "100%|███████████████████████████████| 263508/263508 [00:01<00:00, 144901.68it/s]\r\n",
      "15926\r\n",
      "total: 154892  tuple_sent_amr_level\r\n",
      "Running on the GPU\r\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at Wikidepia/IndoT5-base and are newly initialized: ['encoder.tree_embed.weight']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "added 9 tokens\r\n",
      "len train dataset:  154892\r\n",
      "len dev dataset:  19\r\n",
      "len test dataset: 306\r\n",
      "len train dataloader:  38723\r\n",
      "(Epoch 1) TRAIN LOSS:0.9381 LR:0.00010000: 100%|█| 38723/38723 [1:51:30<00:00,  \r\n",
      "(Epoch 1) DEV LOSS:2.7317 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 19.42it/s]\r\n",
      "bleu score on dev:  22.19550724949194\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:22<00:00,  3.45it/s]\r\n",
      "sample:  ilham meniup balon. ---- balon itu ditiup ilham\r\n",
      "sample:  obe menulis puisi. ---- obe menulis puisi\r\n",
      "sample:  saya mengetik makalah. ---- saya mengetik makalah\r\n",
      "sample:  angga anak ajaib. ---- angga anak ajaib\r\n",
      "sample:  ibu saya orang dosen. ---- ibuku seorang dosen\r\n",
      "bleu score on test dataset:  38.4940352425778\r\n"
     ]
    }
   ],
   "source": [
    "!chmod +x train_indoT5_on_silver_data.sh\n",
    "!./train_indoT5_on_silver_data.sh linearized_penman_with_tree_level ../amr-indo-dataset/data_154k_raw_silver_amr_indo4b_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d900adf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T12:31:12.101086Z",
     "iopub.status.busy": "2022-05-18T12:31:12.097223Z",
     "iopub.status.idle": "2022-05-18T12:34:29.309567Z",
     "shell.execute_reply": "2022-05-18T12:34:29.308900Z"
    },
    "papermill": {
     "duration": 240.355222,
     "end_time": "2022-05-18T12:34:29.309737",
     "exception": false,
     "start_time": "2022-05-18T12:30:28.954515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\r\n",
      "resume from checkpoint\r\n",
      "added 0 tokens\r\n",
      "len train dataset:  2648\r\n",
      "len dev dataset:  19\r\n",
      "len test dataset: 306\r\n",
      "len train dataloader:  662\r\n",
      "(Epoch 1) TRAIN LOSS:0.7940 LR:0.00010000: 100%|█| 662/662 [01:21<00:00,  8.10it\r\n",
      "(Epoch 1) DEV LOSS:0.9519 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 29.70it/s]\r\n",
      "bleu score on dev:  38.94849613360894\r\n",
      "(Epoch 2) TRAIN LOSS:0.4593 LR:0.00010000: 100%|█| 662/662 [01:21<00:00,  8.15it\r\n",
      "(Epoch 2) DEV LOSS:0.9471 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 29.65it/s]\r\n",
      "bleu score on dev:  44.64185459642168\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:17<00:00,  4.44it/s]\r\n",
      "sample:  balon ditiup ilham ---- balon itu ditiup ilham\r\n",
      "sample:  puisi ditulis obe ---- obe menulis puisi\r\n",
      "sample:  makalah diketik oleh saya ---- saya mengetik makalah\r\n",
      "sample:  angga anak ajaib ---- angga anak ajaib\r\n",
      "sample:  ibu seorang dosen ---- ibuku seorang dosen\r\n",
      "bleu score on test dataset:  40.1476808937709\r\n"
     ]
    }
   ],
   "source": [
    "!python train_indoT5.py --model_type indo-t5 --n_epochs 2 --lr 0.0001 --data_folder ../data/preprocessed_data/linearized_penman_with_tree_level  --result_folder result --resume_from_checkpoint True --saved_model_folder_path result/result_supervised_task_adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b22c276",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T12:35:57.950095Z",
     "iopub.status.busy": "2022-05-18T12:35:57.944482Z",
     "iopub.status.idle": "2022-05-18T12:38:03.352155Z",
     "shell.execute_reply": "2022-05-18T12:38:03.351621Z"
    },
    "papermill": {
     "duration": 169.558432,
     "end_time": "2022-05-18T12:38:03.352296",
     "exception": false,
     "start_time": "2022-05-18T12:35:13.793864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model folder result\r\n",
      "preprocessing method linearized_penman_with_tree_level\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data’: File exists\r\n",
      "preprocess amr_simple_test\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/amr_simple_test’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/amr_simple_test/test.amr.txt', result_sent_path='data/test/preprocessed_data/amr_simple_test/test.sent.txt', source_file_path='data/test/amr_simple_test.txt', source_folder_path=None)\r\n",
      "100%|███████████████████████████████████| 2618/2618 [00:00<00:00, 181492.97it/s]\r\n",
      "total: 306  tuple_sent_amr_level\r\n",
      "preprocess b-salah-darat\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/b-salah-darat’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/b-salah-darat/test.amr.txt', result_sent_path='data/test/preprocessed_data/b-salah-darat/test.sent.txt', source_file_path='data/test/b-salah-darat.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 676/676 [00:00<00:00, 125225.22it/s]\r\n",
      "total: 32  tuple_sent_amr_level\r\n",
      "preprocess c-gedung-roboh\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/c-gedung-roboh’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/c-gedung-roboh/test.amr.txt', result_sent_path='data/test/preprocessed_data/c-gedung-roboh/test.sent.txt', source_file_path='data/test/c-gedung-roboh.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 606/606 [00:00<00:00, 133054.92it/s]\r\n",
      "total: 29  tuple_sent_amr_level\r\n",
      "preprocess d-indo-fuji\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/d-indo-fuji’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/d-indo-fuji/test.amr.txt', result_sent_path='data/test/preprocessed_data/d-indo-fuji/test.sent.txt', source_file_path='data/test/d-indo-fuji.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 745/745 [00:00<00:00, 127911.76it/s]\r\n",
      "total: 27  tuple_sent_amr_level\r\n",
      "preprocess f-bunuh-diri\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/f-bunuh-diri’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/f-bunuh-diri/test.amr.txt', result_sent_path='data/test/preprocessed_data/f-bunuh-diri/test.sent.txt', source_file_path='data/test/f-bunuh-diri.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 468/468 [00:00<00:00, 129592.28it/s]\r\n",
      "total: 23  tuple_sent_amr_level\r\n",
      "preprocess g-gempa-dieng\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/g-gempa-dieng’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/g-gempa-dieng/test.amr.txt', result_sent_path='data/test/preprocessed_data/g-gempa-dieng/test.sent.txt', source_file_path='data/test/g-gempa-dieng.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 412/412 [00:00<00:00, 128508.46it/s]\r\n",
      "total: 19  tuple_sent_amr_level\r\n",
      "evaluate on data amr_simple_test\r\n",
      "mkdir: cannot create directory ‘result/amr_simple_test’: File exists\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 306\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:16<00:00,  4.61it/s]\r\n",
      "sample:  balon ditiup ilham ---- balon itu ditiup ilham\r\n",
      "sample:  puisi ditulis obe ---- obe menulis puisi\r\n",
      "sample:  makalah diketik oleh saya ---- saya mengetik makalah\r\n",
      "sample:  angga anak ajaib ---- angga anak ajaib\r\n",
      "sample:  ibu seorang dosen ---- ibuku seorang dosen\r\n",
      "sample:  dia sedang berenang ---- dia sedang berenang\r\n",
      "sample:  ilham mencari buku yang hilang ---- ilham sedang mencari bukunya yang hilang\r\n",
      "sample:  di halaman rumah, ibu menyapu ---- ibu sedang menyapu halaman rumah\r\n",
      "sample:  padi dibajak oleh ayah di sawah ---- ayah sedang membajak padi di sawah\r\n",
      "sample:  andi pergi ke perkemahan di tepi pantai ---- andi pergi berkemah di tepi pantai\r\n",
      "bleu score on test dataset:  40.1476808937709\r\n",
      "evaluate on data b-salah-darat\r\n",
      "mkdir: cannot create directory ‘result/b-salah-darat’: File exists\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 32\r\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:06<00:00,  1.14it/s]\r\n",
      "sample:  kantor bersama dan pt angkasa pura ii dengan otoritas bandara soekarno-hatta dan pt imigrasi bandara soekarno-hatta membahas insiden penumpang penerbangan pesawat yang tiba di jakarta dari lion air jt 161 ---- kantor imigrasi bandara soekarno-hatta bersama kantor otoritas bandara soekarno-hatta dan pt angkasa pura ii membahas insiden penumpang penerbangan pesawat lion air jt 161 yang tiba di jakarta dari singapura 10 mei 2016.\r\n",
      "sample:  kepala kantor imigrasi soekarno-hatta alif suadi menuturkan, kami meeting soal itu kepada tempo pada sabtu malam ini, 14 mei ---- kami meeting soal ini,\" ujar kepala kantor imigrasi soekarno-hatta alif suadi kepada tempo, sabtu malam ini, 14 mei 2016.\r\n",
      "sample:  anak temannya natalie berangkat ke singapura pukul 18: 55 dan menggunakan pesawat lion air jt 161 ---- anak temannya natalie berangkat dari singapura dan menggunakan pesawat lion air jt 161, pada pukul 18.50.\r\n",
      "sample:  sekretaris agus haryadi dari perusahaan pt angkasa pura ii mengatakan, dalam melakukan pengelolaan bandara internasional soekarno-hatta, pihaknya akan berkoordinasi dengan kantor otoritas bandara wilayah 1 terkait perisitiwa ---- sekretaris perusahaan pt angkasa pura ii agus haryadi mengatakan selaku pengelola bandara internasional soekarno-hatta, pihaknya akan berkoordinasi dengan kantor otoritas bandara wilayah i terkait dengan peristiwa ini.\r\n",
      "sample:  di remote area, kami menyiapkan bus antar penumpang dari terminal ---- setiap pesawat yang parkir di remote area sudah kami siapkan bus untuk mengantar penumpang ke terminal.\r\n",
      "sample:  edward menuturkan, terdapat seorang sopir yang menjemput penumpang di padang dengan bus ---- terdapat sopir bus yang akan menjemput penumpang dari padang\" ujar edward.\r\n",
      "sample:  pihak otoritas bandara soetta memanggil pihak terkait dan melakukan investigasi ---- pihak otoritas bandara soetta akan memanggil pihak terkait dan dilakukan investigasi.\r\n",
      "sample:  kemenhub memberikan sanksi kepada pihak-pihak yang lalai ---- kemenhub memberikan sanksi kepada pihak-pihak yang lalai,\" ujarnya.\r\n",
      "sample:  zara mengatakan, zara mengutip cerita temannya bahwa pesawat itu tidak mendarat di terminal ii ---- pesawat itu mendarat tidak di terminal ii, kata zara mengutip cerita temannya.\r\n",
      "sample:  di remote area, kami menyiapkan bus antar penumpang dari terminal ---- setiap pesawat yang parkir di remote area sudah kami siapkan bus untuk mengantar penumpang ke terminal.\r\n",
      "bleu score on test dataset:  29.957613769079718\r\n",
      "evaluate on data c-gedung-roboh\r\n",
      "mkdir: cannot create directory ‘result/c-gedung-roboh’: File exists\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 29\r\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:05<00:00,  1.39it/s]\r\n",
      "sample:  pengalihan kendaraan yang melaju dari arah mal bintaro xchange dan tol bintaro menuju jalan boulevard bintaro dilakukan dengan menggunakan flyover di atas lampu indomobil merah ---- pengalihan dilakukan bagi pengendara yang melaju dari arah mal bintaro xchange dan tol bintaro menuju jalan boulevard bintaro dengan menggunakan flyover di atas lampu merah indomobil.\r\n",
      "sample:  kegagalan dan kesalahan tes tanah mengakibatkan struktur menjadi miring terjadi di menara saidah di jalan mt haryono, jakarta timur ---- kegagalan struktur dan kesalahan tes tanah yang mengakibatkan gedung miring juga terjadi pada menara saidah di jalan mt haryono, jakarta timur.\r\n",
      "sample:  kapolres ayi supardan akbp di tangerang selatan membenarkan peristiwa di bintaro robohnya gedung menarik hati masyarakat banyak ---- kapolres tangerang selatan, akbp ayi supardan membenarkan peristiwa robohnya gedung di bintaro yang menarik perhatian masyarakat banyak.\r\n",
      "sample:  panin memutuskan melanjutkan pembangunan gedung tersebut dikarenakan dinyatakan tidak lulus uji kelayakan ---- panin memutuskan tidak melanjutkan pembangunan gedung itu karena dinyatakan tidak lulus uji kelayakan.\r\n",
      "sample:  gedung tersebut dinyatakan tidak lulus ujian sehingga pembangunan gedung tersebut diputuskan untuk tidak dilanjutkan ---- gedung tersebut dinyatakan tidak lulus uji sehingga pembangunan gedung diputuskan tidak dilanjutkan.\r\n",
      "sample:  kasat akp samian dari polres tangerang selatan kepada reskrim mengatakan, saat ini pihaknya sedang melakukan penyelidikan. ---- kasat reskrim polres tangerangg selatan, akp samian mengatakan saat ini pihaknya melakukan penyelidikan untuk mengetahui penyebab runtuhnya gedung.\r\n",
      "sample:  hingga ini, kami masih mendalami peristiwa yang disebut ---- hingga kini kami masih mendalami peristiwa tersebut.\r\n",
      "sample:  disebut tidak terjadi korban ---- kejadian tersebut tidak timbul korban.\r\n",
      "sample:  terjadi kerugian material ---- terjadi kerugian material.\r\n",
      "sample:  pembongkaran di sektor 7 bintaro, tangerang selatan, diduga gedung tersebut menyalahi prosedur ---- pembongkaran gedung di sektor 7, bintaro, tangerang selatan, diduga menyalahi prosedur.\r\n",
      "bleu score on test dataset:  34.55966540459924\r\n",
      "evaluate on data d-indo-fuji\r\n",
      "mkdir: cannot create directory ‘result/d-indo-fuji’: File exists\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 27\r\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:06<00:00,  1.13it/s]\r\n",
      "sample:  indosat ooredoo menandatangani nota kesepahaman dengan fujitsu indonesia dalam rangka memantapkan mitra pembangunan yang telah dibangun untuk pelanggan bisnis, di dalam yang hadir solusi smart dan internet of things mobility ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah dibangun dalam menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  indosat ooredoo menandatangani nota kesepahaman dengan fujitsu indonesia dalam rangka memantapkan mitra pembangunan yang telah dibangun untuk pelanggan bisnis, di dalam yang hadir solusi smart dan internet of things mobility ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah dibangun dalam menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  smart mobility dan iot mengalami perkembangan cukup signifikan hingga mengubah cara perusahaan di dalam mengelola aset ---- smart mobility dan iot mengalami perkembangan cukup signifikan sehingga mengubah cara perusahaan dalam mengelola aset.\r\n",
      "sample:  indosat ooredoo menandatangani nota kesepahaman dengan fujitsu indonesia dalam rangka memantapkan mitra pembangunan yang telah dibangun untuk pelanggan bisnis, di dalam yang hadir solusi smart dan internet of things mobility ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  kerja sama difokuskan pada sektor transportasi dan otomotif dan diperluas untuk sektor industri dan sebagainya untuk memenuhi kebutuhan pelanggan korporasi di indonesia ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "sample:  president achmad sofwan sebagai director fujitsu indonesia menuturkan, mobilitas memanfaatkan layanan aplikasi dan memproses data real-time sebagai cara mengoptimalkan strategi perusahaan ---- mobilitas akan menyediakan cara untuk mengoptimalkan strategi perusahaan dengan memanfaatkan aplikasi dan layanan yang dapat memproses data real-time, tutur achmad sofwan, president director fujitsu indonesia.\r\n",
      "sample:  kerja sama difokuskan pada sektor transportasi dan otomotif dan diperluas untuk sektor industri dan sebagainya untuk memenuhi kebutuhan pelanggan korporasi di indonesia ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "sample:  indosat ooredoo bekerja sama dengan indosat di indonesia untuk menghadirkan solusi smart mobility dan internet of things ---- indosat ooredoo bekerja sama dengan fujitsu indonesia menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  president achmad sofwan sebagai director fujitsu mengungkapkan, mobilitasnya memanfaatkan layanan aplikasi dan memproses data real-time dengan cara mengoptimalkan strategi perusahaan ---- president director fujitsu, achmad sofwan mengungkap, mobilitas akan menyediakan cara mengoptimalisasikan strategi perusahaan dengan memanfaatkan aplikasi dan layanan dalam aktivitas memproses data real-time.\r\n",
      "sample:  kerja sama difokuskan pada sektor transportasi dan otomotif dan diperluas untuk sektor industri dan sebagainya untuk memenuhi kebutuhan pelanggan korporasi di indonesia ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "bleu score on test dataset:  27.537857284415264\r\n",
      "evaluate on data f-bunuh-diri\r\n",
      "mkdir: cannot create directory ‘result/f-bunuh-diri’: File exists\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 23\r\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:05<00:00,  1.20it/s]\r\n",
      "sample:  ciptadi melompat di megatron jembatan yang tingginya diperkirakan mencapai 15 meter yang menyeberang orang itu ---- ciptadi dengan nekat melompat dari megatron jembatan penyeberangan orang yang tingginya diperkirakan mencapai 15 meter.\r\n",
      "sample:  hal yang disebut diungkapkan kasubag reny marthaliana dari humas kompol mengungkapkan kabag dede rojudin dari kompol ops polrestabes bandung pada jumat di mapolrestabes bandung ---- hal tersebut diungkapkan kabag ops polrestabes bandung kompol dede rojudin didampingi kasubag humas kompol reny marthaliana, saat ditemui di mapolrestabes bandung, jumat.\r\n",
      "sample:  rezha, warga kota bandung yang noviana katakan, telah usai salat jumat ia dan jemaat lainnya memperhatikan megatron di depan kantor pos besar bandung di jembatan penyeberangan orang ---- rezha noviana, warga kota bandung mengatakan ia dan jemaat lainnya langsung memperhatikan megatron jembatan penyeberangan orang depan kantor pos besar bandung setelah bubar salat jumat di masjid raya bandung.\r\n",
      "sample:  di atas jpo, petugas linmas dan satpam berapa berdiri ---- ketika itu, petugas linmas dan beberapa satpam berdiri di atas jpo.\r\n",
      "sample:  di alun-alun bandung, aksi bunuh diri terjadi belum lama ini ---- aksi bunuh diri di alun - alun bandung belum lama ini terjadi.\r\n",
      "sample:  orang tua itu terjatuh dari jpo di alun kota bandung ---- seorang pria tua nekat menjatuhkan diri dari jpo di alun - alun kota bandung.\r\n",
      "sample:  sudirman yang menjadi saksi mata pembunuhan di alun-alun bandung mengatakan dirinya adalah anggota linmas kota bandung dari satpol pp mengatakan, pria yang disebutnya diperkirakan berusia 30 tahun itu ---- sudirman, anggota linmas satpol pp kota bandung yang menjadi saksi mata aksi bunuh diri di alun - alun bandung itu mengatakan, pria tersebut diperkirakan berusia 50 tahun.\r\n",
      "sample:  jumat, lelaki itu menjatuhkan diri di megatron di depan pos giro besar bandung di jembatan penyeberangan ---- seorang lelaki menjatuhkan diri dari megatron jembatan penyeberangan di depan pos giro besar bandung, bandung, jumat.\r\n",
      "sample:  lelaki setengah baya itu mengakhiri hidupnya di tengah lalu lintas di jalan asia afrika ---- seorang lelaki tengah baya nekat mengakhiri hidupnya di tengah kepadatan lalu lintas jalan asia afrika.\r\n",
      "sample:  pria misterius yang bunuh diri di jembatan penyeberangan orang di bandung, jawa barat, di asia afrika, membuat dirinya belum terjun secara nekat ---- pria misterius yang bunuh diri dari jembatan penyeberangan orang di jalan asia afrika, bandung, jawa barat, membuat pesan sebelum nekat terjun.\r\n",
      "bleu score on test dataset:  29.168171620649776\r\n",
      "evaluate on data g-gempa-dieng\r\n",
      "mkdir: cannot create directory ‘result/g-gempa-dieng’: File exists\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 19\r\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:04<00:00,  1.21it/s]\r\n",
      "sample:  stasiun di banjarnegara, jawa tengah, badan meteorologi klimatologi geofisika menyatakan gempa berkekuatan 4, 8 skala richter mengguncang dataran tinggi dieng pada pukul 19: 00 wib ---- stasiun geofisika badan meteorologi klimatologi dan geofisika banjarnegara, jawa tengah, menyatakan bahwa gempa yang mengguncang dataran tinggi dieng pukul 19.00 wib berkekuatan 4,8 pada skala richter.\r\n",
      "sample:  pusat gempa diperkirakan berada di desa di kecamatan di kabupaten batang bawang, tanji gugur ---- pusat gempa diperkirakan berada di desa tanji gugur, kecamatan bawang, kabupaten batang.\r\n",
      "sample:  pvmbg merekomendasikan agar sementara jalan yang berdekatan dengan kawah di desa sumberejo dipertimbangkan ditutup seluruhnya ---- pvmbg merekomendasikan seluruh jalan yang mendekati kawah timbang di desa sumberejo sementara ditutup.\r\n",
      "sample:  kepala pusat vulkanologi mitigasi bencana geologi mengatakan, surono merekam sebanyak 86 kali gempa yang terjadi pada pukul 19. 00 wib di dataran tinggi dieng ---- kepala pusat vulkanologi dan mitigasi bencana geologi surono mengatakan bahwa gempa yang terjadi di dataran tinggi dieng pukul 19.00 wib terekam sebanyak 86 kali.\r\n",
      "sample:  penutupan dilakukan hingga tim yang mengukur konsentrasi gas di lapangan menyatakan tidak ada gas berbahaya ---- penutupan ini dilakukan hingga tim di lapangan yang mengukur konsentrasi gas menyatakan tidak ada gas yang berbahaya.\r\n",
      "sample:  pvmbg merekomendasikan agar sementara jalan yang berdekatan dengan kawah di desa sumberejo dipertimbangkan ditutup seluruhnya ---- pvmbg merekomendasikan seluruh jalan yang mendekati kawah timbang di desa sumberejo sementara ditutup.\r\n",
      "sample:  petugas dari pusat vulkanologi mitigasi bencana geologi diterjunkan untuk memantau aktivitas kawah timbang dan memberikan informasi ---- petugas pusat vulkanologi dan mitigasi bencana geologi diterjunkan untuk memantau aktivitas kawah timbang dan memberikan informasi.\r\n",
      "sample:  data yang dikeluarkan oleh pusat vulkanologi mitigasi bencana geologi menyebutkan dan telah merekam gempa sebanyak 86 kali sejak gempa dirasakan pada pukul 19: 00 wib ---- data yang dikeluarkan dari pusat vulkanologi dan mitigasi bencana geologi menyebutkan gempa mulai terasa pukul 19.00 wib dan telah terekam gempa sebanyak 86 kali.\r\n",
      "sample:  pengungsi di kabupaten banjarnegara meninggal ketika sabtu pagi ---- pengungsi di kabupaten banjarnegara, pada sabtu pagi mulai meninggalkan pengungsian.\r\n",
      "sample:  stasiun banjarnegara dari badan meteorologi klimatologi geofisika menyatakan gempa berkekuatan 4, 8 skala richter mengguncang dataran tinggi dieng pada pukul 19: 00 wib ---- stasiun geofisika badan meteorologi klimatologi dan geofisika banjarnegara menyatakan gempa yang mengguncang dataran tinggi dieng pukul 19.00 wib berkekuatan 4,8 skala richter *(sr)*.\r\n",
      "bleu score on test dataset:  33.3298543937789\r\n"
     ]
    }
   ],
   "source": [
    "!chmod +x ./evaluate_indoT5_to_all.sh\n",
    "!./evaluate_indoT5_to_all.sh result linearized_penman_with_tree_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9009f948",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T12:39:31.818260Z",
     "iopub.status.busy": "2022-05-18T12:39:31.817438Z",
     "iopub.status.idle": "2022-05-18T12:41:31.651900Z",
     "shell.execute_reply": "2022-05-18T12:41:31.652305Z"
    },
    "papermill": {
     "duration": 164.464879,
     "end_time": "2022-05-18T12:41:31.652479",
     "exception": false,
     "start_time": "2022-05-18T12:38:47.187600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: result/ (stored 0%)\r\n",
      "  adding: result/f-bunuh-diri/ (stored 0%)\r\n",
      "  adding: result/f-bunuh-diri/test_generations.txt (deflated 66%)\r\n",
      "  adding: result/f-bunuh-diri/test_label.txt (deflated 68%)\r\n",
      "  adding: result/f-bunuh-diri/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/amr_simple_test/ (stored 0%)\r\n",
      "  adding: result/amr_simple_test/test_generations.txt (deflated 63%)\r\n",
      "  adding: result/amr_simple_test/test_label.txt (deflated 60%)\r\n",
      "  adding: result/amr_simple_test/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/c-gedung-roboh/ (stored 0%)\r\n",
      "  adding: result/c-gedung-roboh/test_generations.txt (deflated 62%)\r\n",
      "  adding: result/c-gedung-roboh/test_label.txt (deflated 62%)\r\n",
      "  adding: result/c-gedung-roboh/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/d-indo-fuji/ (stored 0%)\r\n",
      "  adding: result/d-indo-fuji/test_generations.txt (deflated 85%)\r\n",
      "  adding: result/d-indo-fuji/test_label.txt (deflated 86%)\r\n",
      "  adding: result/d-indo-fuji/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/test_generations.txt (deflated 63%)\r\n",
      "  adding: result/model/ (stored 0%)\r\n",
      "  adding: result/model/pytorch_model.bin (deflated 9%)\r\n",
      "  adding: result/model/config.json (deflated 45%)\r\n",
      "  adding: result/loss_data.tsv (deflated 19%)\r\n",
      "  adding: result/tokenizer/ (stored 0%)\r\n",
      "  adding: result/tokenizer/tokenizer_config.json (deflated 81%)\r\n",
      "  adding: result/tokenizer/added_tokens.json (deflated 43%)\r\n",
      "  adding: result/tokenizer/special_tokens_map.json (deflated 83%)\r\n",
      "  adding: result/tokenizer/spiece.model (deflated 49%)\r\n",
      "  adding: result/b-salah-darat/ (stored 0%)\r\n",
      "  adding: result/b-salah-darat/test_generations.txt (deflated 65%)\r\n",
      "  adding: result/b-salah-darat/test_label.txt (deflated 66%)\r\n",
      "  adding: result/b-salah-darat/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/test_label.txt (deflated 60%)\r\n",
      "  adding: result/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/g-gempa-dieng/ (stored 0%)\r\n",
      "  adding: result/g-gempa-dieng/test_generations.txt (deflated 66%)\r\n",
      "  adding: result/g-gempa-dieng/test_label.txt (deflated 67%)\r\n",
      "  adding: result/g-gempa-dieng/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/result_supervised_task_adaptation/ (stored 0%)\r\n",
      "  adding: result/result_supervised_task_adaptation/test_generations.txt (deflated 64%)\r\n",
      "  adding: result/result_supervised_task_adaptation/model/ (stored 0%)\r\n",
      "  adding: result/result_supervised_task_adaptation/model/pytorch_model.bin (deflated 9%)\r\n",
      "  adding: result/result_supervised_task_adaptation/model/config.json (deflated 45%)\r\n",
      "  adding: result/result_supervised_task_adaptation/loss_data.tsv (deflated 3%)\r\n",
      "  adding: result/result_supervised_task_adaptation/tokenizer/ (stored 0%)\r\n",
      "  adding: result/result_supervised_task_adaptation/tokenizer/tokenizer_config.json (deflated 81%)\r\n",
      "  adding: result/result_supervised_task_adaptation/tokenizer/added_tokens.json (deflated 43%)\r\n",
      "  adding: result/result_supervised_task_adaptation/tokenizer/special_tokens_map.json (deflated 82%)\r\n",
      "  adding: result/result_supervised_task_adaptation/tokenizer/spiece.model (deflated 49%)\r\n",
      "  adding: result/result_supervised_task_adaptation/test_label.txt (deflated 60%)\r\n",
      "  adding: result/result_supervised_task_adaptation/bleu_score_test.txt (stored 0%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r result_with_sta.zip result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16953.29526,
   "end_time": "2022-05-18T12:42:16.647793",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-18T07:59:43.352533",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
